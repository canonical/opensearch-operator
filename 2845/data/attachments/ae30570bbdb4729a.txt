[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/3 [idle] active: 
  opensearch/4 [idle] active: 
  opensearch/5 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/3 [idle] active: 
  opensearch/4 [idle] active: 
  opensearch/5 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/3 [idle] active: 
  opensearch/4 [idle] active: 
  opensearch/5 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/5 [executing] maintenance: Installing OpenSearch...
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/5 [executing] maintenance: Installing OpenSearch...
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/3 [idle] active: 
  opensearch/4 [idle] active: 
  opensearch/5 [executing] maintenance: Waiting for TLS to be fully configured...
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/3 [executing] active: 
  opensearch/4 [executing] active: 
  opensearch/5 [executing] active: 
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/3 [idle] active: 
  opensearch/4 [idle] active: 
  opensearch/5 [idle] active: 
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/3 [idle] active: 
  opensearch/4 [idle] active: 
  opensearch/5 [idle] active: 
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:329 



[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:330 Model  Controller           Cloud/Region         Version  SLA          Timestamp
test   localhost-localhost  localhost/localhost  3.5.3    unsupported  02:26:24Z

App                       Version  Status   Scale  Charm                     Channel        Rev  Exposed  Message
opensearch                         waiting    0/1  opensearch                                 1  no       waiting for machine
self-signed-certificates           active       1  self-signed-certificates  latest/stable  155  no       

Unit                         Workload  Agent       Machine  Public address  Ports  Message
opensearch/6                 waiting   allocating  7                               waiting for machine
self-signed-certificates/0*  active    executing   0        10.56.239.191          

Machine  State    Address        Inst id        Base          AZ  Message
0        started  10.56.239.191  juju-ceaaf4-0  ubuntu@22.04      Running
7        pending                 pending        ubuntu@22.04      

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:26:24 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:251 opensearch -- expected units: 1 -- current: 0
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:26:34 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch waiting -- message: waiting for machine
		opensearch-6.bdb  -- (10.56.239.96) -- [allocating (since: 02:26:23)] waiting: waiting for machine

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:27:48 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Installing OpenSearch...
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:27:43)] maintenance: Installing OpenSearch...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:27:58 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Installing OpenSearch...
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:27:43)] maintenance: Installing OpenSearch...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:28:09 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Installing OpenSearch...
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:27:43)] maintenance: Installing OpenSearch...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:28:20 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Installing OpenSearch...
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:27:43)] maintenance: Installing OpenSearch...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:28:31 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Waiting for TLS to be fully configured...
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:28:28)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:28:41 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch waiting -- message: Waiting for OpenSearch to start...
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:28:38)] waiting: Waiting for OpenSearch to start...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:28:52 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch waiting -- message: Waiting for OpenSearch to start...
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:28:38)] waiting: Waiting for OpenSearch to start...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:29:03 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:28:56)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:29:13 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:28:56)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:29:24 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:28:56)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:29:35 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:28:56)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:29:46 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:28:56)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:29:56 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:28:56)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:30:07 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:28:56)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:30:18 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:28:56)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:30:29 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:28:56)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:30:39 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:28:56)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:30:50 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:28:56)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:31:01 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:28:56)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:31:11 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:28:56)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:31:22 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:28:56)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:31:33 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:28:56)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:31:43 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:28:56)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:31:54 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:28:56)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:32:05 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:32:05)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:32:16 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:32:12)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:32:26 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:32:12)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:32:37 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:32:12)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:32:48 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:32:12)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:32:58 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:32:12)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:33:09 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:32:12)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:33:20 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:32:12)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:33:30 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:348 02:33:31 -- Waiting for model: complete.



[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:329 



[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:330 Model  Controller           Cloud/Region         Version  SLA          Timestamp
test   localhost-localhost  localhost/localhost  3.5.3    unsupported  02:33:32Z

App                       Version  Status   Scale  Charm                     Channel        Rev  Exposed  Message
opensearch                         blocked    1/3  opensearch                                 1  no       1 or more 'replica' shards are not assigned, please scale your application up.
self-signed-certificates           active       1  self-signed-certificates  latest/stable  155  no       

Unit                         Workload  Agent       Machine  Public address  Ports     Message
opensearch/6*                active    idle        7        10.56.239.96    9200/tcp  
opensearch/7                 waiting   allocating  8                                  waiting for machine
opensearch/8                 waiting   allocating  9                                  waiting for machine
self-signed-certificates/0*  active    idle        0        10.56.239.191             

Machine  State    Address        Inst id        Base          AZ  Message
0        started  10.56.239.191  juju-ceaaf4-0  ubuntu@22.04      Running
7        started  10.56.239.96   juju-ceaaf4-7  ubuntu@22.04      Running
8        pending                 pending        ubuntu@22.04      
9        pending                 pending        ubuntu@22.04      

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:33:32 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:251 opensearch -- expected units: 3 -- current: 1
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:33:42 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:32:12)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [allocating (since: 02:33:31)] waiting: waiting for machine
		opensearch-8.bdb  -- (10.56.239.160) -- [allocating (since: 02:33:31)] waiting: waiting for machine

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:34:58 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:32:12)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:34:50)] maintenance: Installing OpenSearch...
		opensearch-8.bdb  -- (10.56.239.160) -- [executing (since: 02:34:54)] maintenance: Installing OpenSearch...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:35:10 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:32:12)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:34:50)] maintenance: Installing OpenSearch...
		opensearch-8.bdb  -- (10.56.239.160) -- [executing (since: 02:34:54)] maintenance: Installing OpenSearch...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:35:21 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:32:12)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:34:50)] maintenance: Installing OpenSearch...
		opensearch-8.bdb  -- (10.56.239.160) -- [executing (since: 02:34:54)] maintenance: Installing OpenSearch...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:35:33 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:32:12)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:34:50)] maintenance: Installing OpenSearch...
		opensearch-8.bdb  -- (10.56.239.160) -- [executing (since: 02:34:54)] maintenance: Installing OpenSearch...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:35:44 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:32:12)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:34:50)] maintenance: Installing OpenSearch...
		opensearch-8.bdb  -- (10.56.239.160) -- [executing (since: 02:34:54)] maintenance: Installing OpenSearch...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:35:56 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:32:12)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:35:56)] active: 
		opensearch-8.bdb  -- (10.56.239.160) -- [executing (since: 02:34:54)] maintenance: Installing OpenSearch...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:36:08 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:32:12)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:36:05)] waiting: Requesting lock on operation: start
		opensearch-8.bdb  -- (10.56.239.160) -- [executing (since: 02:36:07)] maintenance: Waiting for TLS to be fully configured...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:36:20 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:32:12)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:36:05)] waiting: Requesting lock on operation: start
		opensearch-8.bdb  -- (10.56.239.160) -- [executing (since: 02:36:19)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:36:32 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:32:12)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:36:05)] waiting: Requesting lock on operation: start
		opensearch-8.bdb  -- (10.56.239.160) -- [executing (since: 02:36:31)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:36:43 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:36:42)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:36:05)] waiting: Requesting lock on operation: start
		opensearch-8.bdb  -- (10.56.239.160) -- [executing (since: 02:36:42)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:36:55 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:36:42)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:36:05)] waiting: Requesting lock on operation: start
		opensearch-8.bdb  -- (10.56.239.160) -- [idle (since: 02:36:44)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:37:06 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:36:42)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:36:05)] waiting: Requesting lock on operation: start
		opensearch-8.bdb  -- (10.56.239.160) -- [idle (since: 02:36:44)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:37:19 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:36:42)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:36:05)] waiting: Requesting lock on operation: start
		opensearch-8.bdb  -- (10.56.239.160) -- [idle (since: 02:36:44)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:37:31 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:36:42)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:36:05)] waiting: Requesting lock on operation: start
		opensearch-8.bdb  -- (10.56.239.160) -- [idle (since: 02:36:44)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:37:42 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:36:42)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:36:05)] waiting: Requesting lock on operation: start
		opensearch-8.bdb  -- (10.56.239.160) -- [idle (since: 02:36:44)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:37:54 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:36:42)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:36:05)] waiting: Requesting lock on operation: start
		opensearch-8.bdb  -- (10.56.239.160) -- [idle (since: 02:36:44)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:38:05 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:36:42)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:36:05)] waiting: Requesting lock on operation: start
		opensearch-8.bdb  -- (10.56.239.160) -- [idle (since: 02:36:44)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:38:17 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:36:42)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:36:05)] waiting: Requesting lock on operation: start
		opensearch-8.bdb  -- (10.56.239.160) -- [idle (since: 02:36:44)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:38:29 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:36:42)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:36:05)] waiting: Requesting lock on operation: start
		opensearch-8.bdb  -- (10.56.239.160) -- [idle (since: 02:36:44)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:38:41 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:36:42)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:36:05)] waiting: Requesting lock on operation: start
		opensearch-8.bdb  -- (10.56.239.160) -- [idle (since: 02:36:44)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:38:53 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:36:42)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:36:05)] waiting: Requesting lock on operation: start
		opensearch-8.bdb  -- (10.56.239.160) -- [idle (since: 02:36:44)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:39:04 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:36:42)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:36:05)] waiting: Requesting lock on operation: start
		opensearch-8.bdb  -- (10.56.239.160) -- [idle (since: 02:36:44)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:39:16 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:36:42)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:36:05)] waiting: Waiting for OpenSearch to start...
		opensearch-8.bdb  -- (10.56.239.160) -- [idle (since: 02:36:44)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:39:28 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:39:27)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:39:27)] active: 
		opensearch-8.bdb  -- (10.56.239.160) -- [executing (since: 02:39:25)] waiting: Waiting for OpenSearch to start...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:39:40 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [executing (since: 02:39:39)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [executing (since: 02:39:40)] active: 
		opensearch-8.bdb  -- (10.56.239.160) -- [executing (since: 02:39:25)] waiting: Waiting for OpenSearch to start...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:39:52 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:39:51)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [idle (since: 02:39:50)] active: 
		opensearch-8.bdb  -- (10.56.239.160) -- [idle (since: 02:39:50)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:40:03 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:39:51)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [idle (since: 02:39:50)] active: 
		opensearch-8.bdb  -- (10.56.239.160) -- [idle (since: 02:39:50)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:40:15 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:39:51)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [idle (since: 02:39:50)] active: 
		opensearch-8.bdb  -- (10.56.239.160) -- [idle (since: 02:39:50)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:40:27 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:39:51)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [idle (since: 02:39:50)] active: 
		opensearch-8.bdb  -- (10.56.239.160) -- [idle (since: 02:39:50)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:40:38 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:39:51)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [idle (since: 02:39:50)] active: 
		opensearch-8.bdb  -- (10.56.239.160) -- [idle (since: 02:39:50)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:40:50 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:39:51)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [idle (since: 02:39:50)] active: 
		opensearch-8.bdb  -- (10.56.239.160) -- [idle (since: 02:39:50)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:41:02 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.bdb* -- (10.56.239.96) -- [idle (since: 02:39:51)] active: 
		opensearch-7.bdb  -- (10.56.239.253) -- [idle (since: 02:39:50)] active: 
		opensearch-8.bdb  -- (10.56.239.160) -- [idle (since: 02:39:50)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:41:14 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:348 02:41:15 -- Waiting for model: complete.
[32mINFO    [0m integration.ha.conftest:conftest.py:48 



The writes have been cleared.




[32mINFO    [0m pytest_operator.plugin:plugin.py:862 Model status:

Model  Controller           Cloud/Region         Version  SLA          Timestamp
test   localhost-localhost  localhost/localhost  3.5.3    unsupported  02:42:45Z

App                       Version  Status  Scale  Charm                     Channel        Rev  Exposed  Message
opensearch                         active      3  opensearch                                 1  no       
self-signed-certificates           active      1  self-signed-certificates  latest/stable  155  no       

Unit                         Workload  Agent  Machine  Public address  Ports     Message
opensearch/6*                active    idle   7        10.56.239.96    9200/tcp  
opensearch/7                 active    idle   8        10.56.239.253   9200/tcp  
opensearch/8                 active    idle   9        10.56.239.160   9200/tcp  
self-signed-certificates/0*  active    idle   0        10.56.239.191             

Machine  State    Address        Inst id        Base          AZ  Message
0        started  10.56.239.191  juju-ceaaf4-0  ubuntu@22.04      Running
7        started  10.56.239.96   juju-ceaaf4-7  ubuntu@22.04      Running
8        started  10.56.239.253  juju-ceaaf4-8  ubuntu@22.04      Running
9        started  10.56.239.160  juju-ceaaf4-9  ubuntu@22.04      Running

[32mINFO    [0m pytest_operator.plugin:plugin.py:868 Juju error logs:

machine-0: 01:39:30 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-0: 01:39:30 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-self-signed-certificates-0: 01:39:30 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-1: 01:39:46 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 01:39:46 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-opensearch-0: 01:39:46 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-opensearch-0: 01:41:56 ERROR unit.opensearch/0.juju-log certificates:3: Cannot connect to the OpenSearch server...
unit-opensearch-0: 01:41:56 ERROR unit.opensearch/0.juju-log certificates:3: Cannot connect to the OpenSearch server...
unit-opensearch-0: 01:41:56 ERROR unit.opensearch/0.juju-log certificates:3: Cannot connect to the OpenSearch server...
unit-opensearch-0: 01:41:59 ERROR unit.opensearch/0.juju-log certificates:3: Cannot connect to the OpenSearch server...
unit-opensearch-0: 01:42:02 ERROR unit.opensearch/0.juju-log certificates:3: Cannot connect to the OpenSearch server...
unit-opensearch-0: 01:42:05 ERROR unit.opensearch/0.juju-log certificates:3: Cannot connect to the OpenSearch server...
unit-opensearch-0: 01:42:08 ERROR unit.opensearch/0.juju-log certificates:3: Cannot connect to the OpenSearch server...
machine-2: 01:44:59 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 01:44:59 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-opensearch-1: 01:44:59 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-opensearch-1: 01:46:07 ERROR unit.opensearch/1.juju-log opensearch-peers:1: Cannot connect to the OpenSearch server...
unit-opensearch-1: 01:49:10 ERROR unit.opensearch/1.juju-log opensearch-peers:1: Cannot connect to the OpenSearch server...
unit-opensearch-1: 01:50:12 ERROR unit.opensearch/1.juju-log Cannot connect to the OpenSearch server...
machine-3: 01:55:42 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 01:55:42 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-opensearch-2: 01:55:42 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-opensearch-2: 01:58:39 ERROR unit.opensearch/2.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:02:04 ERROR unit.opensearch/2.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:04:57 ERROR unit.opensearch/2.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:05:50 ERROR juju.worker.uniter resolver loop error: preparing operation "run storage-detaching (opensearch-data/0) hook" for opensearch/0: secret "secret:crocemmmpb620d4keso0" not found (not found)
unit-opensearch-0: 02:05:50 ERROR juju.worker.dependency "uniter" manifold worker returned unexpected error: preparing operation "run storage-detaching (opensearch-data/0) hook" for opensearch/0: secret "secret:crocemmmpb620d4keso0" not found (not found)
unit-opensearch-0: 02:06:00 ERROR unit.opensearch/0.juju-log Cannot connect to the OpenSearch server...
machine-4: 02:08:02 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-4: 02:08:02 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-opensearch-3: 02:08:02 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-opensearch-3: 02:09:07 ERROR unit.opensearch/3.juju-log certificates:3: Cannot connect to the OpenSearch server...
unit-opensearch-3: 02:09:07 ERROR unit.opensearch/3.juju-log certificates:3: Cannot connect to the OpenSearch server...
machine-5: 02:13:58 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-5: 02:13:58 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-opensearch-4: 02:13:58 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-opensearch-4: 02:15:02 ERROR unit.opensearch/4.juju-log certificates:3: Cannot connect to the OpenSearch server...
unit-opensearch-4: 02:18:05 ERROR unit.opensearch/4.juju-log certificates:3: Cannot connect to the OpenSearch server...
machine-6: 02:21:34 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-6: 02:21:34 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-opensearch-5: 02:21:34 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-opensearch-5: 02:23:10 ERROR unit.opensearch/5.juju-log opensearch-peers:1: Cannot connect to the OpenSearch server...
unit-opensearch-5: 02:23:11 ERROR unit.opensearch/5.juju-log opensearch-peers:1: Cannot connect to the OpenSearch server...
unit-opensearch-3: 02:25:03 ERROR juju.worker.uniter resolver loop error: preparing operation "run relation-departed (0; unit: opensearch/4, departee: opensearch/3) hook" for opensearch/3: secret "secret:crocrfmmpb620d4ket1g" not found (not found)
unit-opensearch-3: 02:25:03 ERROR juju.worker.dependency "uniter" manifold worker returned unexpected error: preparing operation "run relation-departed (0; unit: opensearch/4, departee: opensearch/3) hook" for opensearch/3: secret "secret:crocrfmmpb620d4ket1g" not found (not found)
unit-opensearch-5: 02:25:11 ERROR unit.opensearch/5.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-4: 02:25:11 ERROR unit.opensearch/4.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-3: 02:25:14 ERROR unit.opensearch/3.juju-log Failed to add voting exclusion: opensearch-3.bdb.
unit-opensearch-3: 02:25:30 ERROR unit.opensearch/3.juju-log Cannot connect to the OpenSearch server...
machine-7: 02:27:32 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-7: 02:27:32 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-opensearch-6: 02:27:32 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-opensearch-6: 02:28:39 ERROR unit.opensearch/6.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-6: 02:28:40 ERROR unit.opensearch/6.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-6: 02:28:40 ERROR unit.opensearch/6.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-6: 02:28:43 ERROR unit.opensearch/6.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-6: 02:28:46 ERROR unit.opensearch/6.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-6: 02:28:49 ERROR unit.opensearch/6.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-6: 02:28:52 ERROR unit.opensearch/6.juju-log Cannot connect to the OpenSearch server...
machine-8: 02:34:37 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-8: 02:34:37 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-opensearch-7: 02:34:38 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-9: 02:34:41 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-9: 02:34:41 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-opensearch-8: 02:34:41 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-opensearch-7: 02:36:06 ERROR unit.opensearch/7.juju-log certificates:7: Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:13 ERROR unit.opensearch/8.juju-log opensearch-peers:4: Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:14 ERROR unit.opensearch/8.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:15 ERROR unit.opensearch/8.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:16 ERROR unit.opensearch/8.juju-log opensearch-peers:4: Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:17 ERROR unit.opensearch/8.juju-log upgrade-version-a:6: Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:18 ERROR unit.opensearch/8.juju-log certificates:7: Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:19 ERROR unit.opensearch/8.juju-log certificates:7: Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:21 ERROR unit.opensearch/8.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:22 ERROR unit.opensearch/8.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:23 ERROR unit.opensearch/8.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:24 ERROR unit.opensearch/8.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:25 ERROR unit.opensearch/8.juju-log opensearch-peers:4: Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:26 ERROR unit.opensearch/8.juju-log node-lock-fallback:5: Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:27 ERROR unit.opensearch/8.juju-log node-lock-fallback:5: Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:28 ERROR unit.opensearch/8.juju-log opensearch-peers:4: Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:29 ERROR unit.opensearch/8.juju-log node-lock-fallback:5: Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:30 ERROR unit.opensearch/8.juju-log opensearch-peers:4: Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:32 ERROR unit.opensearch/8.juju-log upgrade-version-a:6: Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:33 ERROR unit.opensearch/8.juju-log upgrade-version-a:6: Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:34 ERROR unit.opensearch/8.juju-log upgrade-version-a:6: Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:35 ERROR unit.opensearch/8.juju-log upgrade-version-a:6: Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:36 ERROR unit.opensearch/8.juju-log node-lock-fallback:5: Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:36:43 ERROR unit.opensearch/8.juju-log opensearch-peers:4: Cannot connect to the OpenSearch server...
unit-opensearch-7: 02:39:09 ERROR unit.opensearch/7.juju-log certificates:7: Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:39:26 ERROR unit.opensearch/8.juju-log upgrade-version-a:6: Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:39:27 ERROR unit.opensearch/8.juju-log upgrade-version-a:6: Cannot connect to the OpenSearch server...

[32mINFO    [0m pytest_operator.plugin:plugin.py:947 Forgetting model main...