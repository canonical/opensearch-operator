[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:329 



[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:330 Model  Controller           Cloud/Region         Version  SLA          Timestamp
test   localhost-localhost  localhost/localhost  3.5.3    unsupported  02:58:48Z

App                       Version  Status   Scale  Charm                     Channel        Rev  Exposed  Message
opensearch                         waiting      3  opensearch                                 0  no       The OpenSearch service is stopping.
self-signed-certificates           active       1  self-signed-certificates  latest/stable  155  no       

Unit                         Workload  Agent      Machine  Public address  Ports     Message
opensearch/0                 active    executing  0        10.206.183.63   9200/tcp  
opensearch/1*                active    executing  1        10.206.183.236  9200/tcp  
opensearch/2                 waiting   executing  2        10.206.183.106  9200/tcp  The OpenSearch service is stopping.
self-signed-certificates/0*  active    idle       3        10.206.183.166            

Machine  State    Address         Inst id        Base          AZ  Message
0        started  10.206.183.63   juju-335105-0  ubuntu@22.04      Running
1        started  10.206.183.236  juju-335105-1  ubuntu@22.04      Running
2        started  10.206.183.106  juju-335105-2  ubuntu@22.04      Running
3        started  10.206.183.166  juju-335105-3  ubuntu@22.04      Running

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:58:48 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch waiting -- message: The OpenSearch service is stopping.
		opensearch-0.093  -- (10.206.183.63) -- [executing (since: 02:58:47)] active: 
		opensearch-1.093* -- (10.206.183.236) -- [executing (since: 02:58:46)] active: 
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 02:58:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:59:00 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [executing (since: 02:58:59)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [executing (since: 02:58:59)] maintenance: Applying new CA certificate...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 02:58:40)] waiting: Waiting for OpenSearch to start...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:59:13 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [executing (since: 02:59:12)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [executing (since: 02:59:12)] maintenance: Applying new CA certificate...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 02:59:12)] waiting: Waiting for OpenSearch to start...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:59:25 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [executing (since: 02:59:24)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [executing (since: 02:59:12)] waiting: The OpenSearch service is stopping.
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 02:59:24)] maintenance: Waiting for TLS to be fully configured...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:59:37 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 02:59:26)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [executing (since: 02:59:12)] waiting: The OpenSearch service stopped.
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 02:59:36)] maintenance: Waiting for TLS to be fully configured...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:59:49 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 02:59:26)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [executing (since: 02:59:12)] waiting: The OpenSearch service stopped.
		opensearch-2.093  -- (10.206.183.106) -- [idle (since: 02:59:46)] maintenance: Waiting for TLS to be fully configured...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:00:01 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 02:59:26)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [executing (since: 02:59:12)] waiting: The OpenSearch service stopped.
		opensearch-2.093  -- (10.206.183.106) -- [idle (since: 02:59:46)] maintenance: Waiting for TLS to be fully configured...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:00:13 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 02:59:26)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [executing (since: 02:59:12)] waiting: The OpenSearch service stopped.
		opensearch-2.093  -- (10.206.183.106) -- [idle (since: 02:59:46)] maintenance: Waiting for TLS to be fully configured...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:00:25 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 02:59:26)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [executing (since: 02:59:12)] waiting: The OpenSearch service stopped.
		opensearch-2.093  -- (10.206.183.106) -- [idle (since: 02:59:46)] maintenance: Waiting for TLS to be fully configured...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:00:37 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 02:59:26)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [executing (since: 02:59:12)] waiting: Waiting for OpenSearch to start...
		opensearch-2.093  -- (10.206.183.106) -- [idle (since: 02:59:46)] maintenance: Waiting for TLS to be fully configured...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:00:49 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 02:59:26)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [executing (since: 02:59:12)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [idle (since: 02:59:46)] maintenance: Waiting for TLS to be fully configured...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:01:01 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:00:58)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:01:00)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:00:51)] waiting: The OpenSearch service stopped.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:01:12 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:00:58)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:01:00)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:00:51)] waiting: The OpenSearch service stopped.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:01:25 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:00:58)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:01:00)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:00:51)] waiting: The OpenSearch service stopped.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:01:37 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:00:58)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:01:00)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:00:51)] waiting: The OpenSearch service stopped.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:01:48 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:00:58)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:01:00)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:00:51)] waiting: The OpenSearch service stopped.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:02:00 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:00:58)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:01:00)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:00:51)] waiting: The OpenSearch service stopped.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:02:12 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:00:51)] waiting: Waiting for OpenSearch to start...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:02:24 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:00:51)] waiting: Waiting for OpenSearch to start...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:02:37 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch error -- message: hook failed: "secret-changed"
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [idle (since: 03:02:35)] error: hook failed: "secret-changed"

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:02:48 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:03:00 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:03:12 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:03:24 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:03:35 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:03:48 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:04:00 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:04:11 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:04:23 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:04:35 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:04:47 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:04:59 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:05:11 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:05:23 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:05:34 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:05:46 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:05:58 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:06:11 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:06:22 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:06:34 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:06:46 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:06:57 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:07:09 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:07:21 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:07:33 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:07:45 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:07:56 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:08:08 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:08:19 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:08:32 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:08:44 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:08:55 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Applying new CA certificate...
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:09:07 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:09:18 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:09:30 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:09:42 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:09:54 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:10:06 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:10:17 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:10:29 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:10:40 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:10:53 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:11:05 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:11:16 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:11:28 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:11:39 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:11:51 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:12:04 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:12:15 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:12:27 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:12:38 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:12:50 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:13:02 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:13:14 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:13:26 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:13:37 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:13:49 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:14:00 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:14:12 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:14:24 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:14:36 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:14:47 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:14:59 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:15:10 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:15:22 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:15:34 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:15:46 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:15:57 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:16:09 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:16:21 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:16:32 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:16:44 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:16:56 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:17:08 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:17:19 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:17:31 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:17:42 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:17:55 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:02:40)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:18:06 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [idle (since: 03:18:01)] error: hook failed: "secret-changed"

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:18:18 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:18:30 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:18:41 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:18:53 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:19:06 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:19:17 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:19:29 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:19:40 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:19:52 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:20:04 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:20:16 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:20:28 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:20:40 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:20:51 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:21:03 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:21:14 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:21:27 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:21:39 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:21:50 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:22:02 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:22:13 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:22:25 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:22:37 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:22:49 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:23:01 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:23:12 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:23:24 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:23:35 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:23:48 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:23:59 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:24:11 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:24:23 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:24:34 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:24:46 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:24:58 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:25:10 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:25:21 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:25:33 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:25:44 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:25:56 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:26:08 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:26:20 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:26:32 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:26:43 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:26:55 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:27:06 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:27:19 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:27:30 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:27:42 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:27:54 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:28:05 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:28:17 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:28:29 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:28:41 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:28:52 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:29:04 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:29:16 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:29:27 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:29:40 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:29:51 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:30:03 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:30:14 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:30:26 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:30:37 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:30:50 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:31:01 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:31:13 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:31:25 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:31:37 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:31:48 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:32:01 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:32:12 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:32:24 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:32:35 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:32:47 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:32:58 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:33:11 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:33:22 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:18:11)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:33:34 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [idle (since: 03:33:29)] error: hook failed: "secret-changed"

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:33:45 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [idle (since: 03:33:29)] error: hook failed: "secret-changed"

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:33:57 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:34:08 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:34:21 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:34:32 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:34:44 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:34:56 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:35:07 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:35:19 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:35:31 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:35:43 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:35:54 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:36:06 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:36:17 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:36:29 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:36:41 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:36:53 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:37:04 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:37:16 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:37:28 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:37:39 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:37:52 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:38:03 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:38:15 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:38:27 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:38:38 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


03:38:49 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Some shards are still initializing / relocating.
		opensearch-0.093  -- (10.206.183.63) -- [idle (since: 03:02:03)] maintenance: Applying new CA certificate...
		opensearch-1.093* -- (10.206.183.236) -- [idle (since: 03:02:03)] maintenance: Waiting for TLS to be fully configured...
		opensearch-2.093  -- (10.206.183.106) -- [executing (since: 03:33:50)] waiting: The OpenSearch service is stopping.

[31m[1mERROR   [0m integration.helpers_deployments:helpers_deployments.py:352 wait_until -- Timed out!



[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:353 Model  Controller           Cloud/Region         Version  SLA          Timestamp
test   localhost-localhost  localhost/localhost  3.5.3    unsupported  03:38:52Z

App                       Version  Status       Scale  Charm                     Channel        Rev  Exposed  Message
opensearch                         maintenance      3  opensearch                                 0  no       Some shards are still initializing / relocating.
self-signed-certificates           active           1  self-signed-certificates  latest/stable  155  no       

Unit                         Workload     Agent      Machine  Public address  Ports     Message
opensearch/0                 maintenance  idle       0        10.206.183.63   9200/tcp  Applying new CA certificate...
opensearch/1*                maintenance  idle       1        10.206.183.236  9200/tcp  Waiting for TLS to be fully configured...
opensearch/2                 waiting      executing  2        10.206.183.106  9200/tcp  The OpenSearch service is stopping.
self-signed-certificates/0*  active       idle       3        10.206.183.166            

Machine  State    Address         Inst id        Base          AZ  Message
0        started  10.206.183.63   juju-335105-0  ubuntu@22.04      Running
1        started  10.206.183.236  juju-335105-1  ubuntu@22.04      Running
2        started  10.206.183.106  juju-335105-2  ubuntu@22.04      Running
3        started  10.206.183.166  juju-335105-3  ubuntu@22.04      Running

[31m[1mERROR   [0m integration.helpers_deployments:helpers_deployments.py:92 Dumping juju logs for all:
[31m[1mERROR   [0m integration.helpers_deployments:helpers_deployments.py:93 unit-opensearch-0: 03:27:51 DEBUG unit.opensearch/0.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:27:51 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:27:51 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-0: 03:27:51 DEBUG unit.opensearch/0.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:27:51 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:27:51 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-0: 03:27:51 DEBUG unit.opensearch/0.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:27:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:27:51 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:27:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-0: 03:27:51 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:27:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-0: 03:27:51 DEBUG unit.opensearch/0.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:27:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:27:51 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:27:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-0: 03:27:51 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:27:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:27:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:27:51 DEBUG unit.opensearch/0.juju-log https://10.206.183.63:9200 "GET /_cluster/state/metadata/voting_config_exclusions HTTP/11" 200 454
unit-opensearch-2: 03:27:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-0: 03:27:51 DEBUG unit.opensearch/0.juju-log Current voting exclusions: {'opensearch-2.093'}
unit-opensearch-2: 03:27:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-0: 03:27:51 DEBUG unit.opensearch/0.juju-log No voting exclusions to delete, current set is {'opensearch-2.093'}
unit-opensearch-2: 03:27:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:27:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:27:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:27:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:27:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-0: 03:27:51 DEBUG unit.opensearch/0.juju-log self._app_workload_container_version='58' self._unit_workload_container_versions={'opensearch/2': '58', 'opensearch/1': '58', 'opensearch/0': '58'}
unit-opensearch-2: 03:27:51 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:27:52 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:27:52 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:27:52 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:27:52 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:27:52 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:27:52 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:27:52 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:27:52 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:27:52 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:27:52 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:27:52 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:27:52 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:27:52 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:27:52 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:27:52 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:27:52 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:27:52 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:27:52 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24079572992, 'free_bytes': 27755528192, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24079572992, 'free_bytes': 27755528192, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24079572992, 'free_bytes': 27755528192, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24079572992, 'free_bytes': 27755528192, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24079572992, 'free_bytes': 27755528192, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24079572992, 'free_bytes': 27755528192, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1624439, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1683610, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:27:52 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-0: 03:27:52 INFO juju.worker.uniter.operation ran "update-status" hook (via hook dispatching script: dispatch)
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:28:02 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:28:02 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24085188608, 'free_bytes': 27749912576, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24085188608, 'free_bytes': 27749912576, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24085188608, 'free_bytes': 27749912576, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24085188608, 'free_bytes': 27749912576, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24085188608, 'free_bytes': 27749912576, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24085188608, 'free_bytes': 27749912576, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1647415, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1698928, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:28:02 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:28:12 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:28:12 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24085188608, 'free_bytes': 27749912576, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24085188608, 'free_bytes': 27749912576, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24085188608, 'free_bytes': 27749912576, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24085188608, 'free_bytes': 27749912576, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24085188608, 'free_bytes': 27749912576, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24085188608, 'free_bytes': 27749912576, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1647415, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1698928, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:28:12 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:28:22 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:28:22 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24085188608, 'free_bytes': 27749912576, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24085188608, 'free_bytes': 27749912576, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24085188608, 'free_bytes': 27749912576, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24085188608, 'free_bytes': 27749912576, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24085188608, 'free_bytes': 27749912576, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24085188608, 'free_bytes': 27749912576, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1647415, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1698928, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:28:22 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-1: 03:28:27 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET /_cluster/health?wait_for_status=green&timeout=1m HTTP/11" 408 463
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-1: 03:28:28 INFO unit.opensearch/1.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}, 'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1662751, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1722175, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[.opensearch-observability][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[.opensearch-observability][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'shard_indexing_pressure_enabled': 'true', 'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-1: 03:28:28 INFO unit.opensearch/1.juju-log Current health of cluster: yellow-temp
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log self._app_workload_container_version='58' self._unit_workload_container_versions={'opensearch/2': '58', 'opensearch/1': '58', 'opensearch/0': '58'}
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Deferring <UpdateStatusEvent via OpenSearchOperatorCharm/on/update_status[445]>.
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log self._app_workload_container_version='58' self._unit_workload_container_versions={'opensearch/2': '58', 'opensearch/1': '58', 'opensearch/0': '58'}
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Re-emitting deferred event <UpdateStatusEvent via OpenSearchOperatorCharm/on/update_status[450]>.
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Executing command: sysctl -n vm.max_map_count
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log sysctl -n vm.max_map_count:
262144

unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Executing command: sysctl -n vm.swappiness
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log sysctl -n vm.swappiness:
0

unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Executing command: sysctl -n net.ipv4.tcp_retries2
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log sysctl -n net.ipv4.tcp_retries2:
5

unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET /_nodes HTTP/11" 200 80467
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET /_cluster/state/metadata/voting_config_exclusions HTTP/11" 200 454
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Current voting exclusions: {'opensearch-2.093'}
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log No voting exclusions to delete, current set is {'opensearch-2.093'}
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:28:28 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:28:32 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:32 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:28:32 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:32 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:32 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:28:32 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:32 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:32 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:28:32 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:32 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:32 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:28:32 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:32 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:32 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:32 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:28:32 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:32 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:32 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:28:32 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:28:32 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:32 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:32 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:28:33 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:33 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:33 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:28:33 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:28:33 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:33 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:33 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:28:33 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:33 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:33 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:28:33 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1662751, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1722175, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:28:33 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:28:43 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:28:43 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1662751, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1722175, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:28:43 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:28:53 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:28:53 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24098623488, 'free_bytes': 27736477696, 'free_disk_percent': 53.5, 'used_disk_percent': 46.5}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1662751, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1722175, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:28:53 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:29:03 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:29:03 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24130859008, 'free_bytes': 27704242176, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24130859008, 'free_bytes': 27704242176, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24130859008, 'free_bytes': 27704242176, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24130859008, 'free_bytes': 27704242176, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24130859008, 'free_bytes': 27704242176, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24130859008, 'free_bytes': 27704242176, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1686030, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1745559, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:29:03 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:29:13 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:29:13 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24130859008, 'free_bytes': 27704242176, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24130859008, 'free_bytes': 27704242176, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24130859008, 'free_bytes': 27704242176, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24130859008, 'free_bytes': 27704242176, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24130859008, 'free_bytes': 27704242176, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24130859008, 'free_bytes': 27704242176, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1686030, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1745559, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:29:14 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:29:24 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:29:24 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24130859008, 'free_bytes': 27704242176, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24130859008, 'free_bytes': 27704242176, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24130859008, 'free_bytes': 27704242176, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24130859008, 'free_bytes': 27704242176, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24130859008, 'free_bytes': 27704242176, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24130859008, 'free_bytes': 27704242176, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1686030, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1745559, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.8gb], shard size: [208b], free after allocating shard: [25.8gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:29:24 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-1: 03:29:28 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET /_cluster/health?wait_for_status=green&timeout=1m HTTP/11" 408 463
unit-opensearch-1: 03:29:28 DEBUG unit.opensearch/1.juju-log Request GET to https://10.206.183.236:9200/_cluster/health?wait_for_status=green&timeout=1m with payload: None failed.(Attempts left: 2)
	Error: 408 Client Error: Request Timeout for url: https://10.206.183.236:9200/_cluster/health?wait_for_status=green&timeout=1m
unit-opensearch-1: 03:29:29 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:29:29 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:29:34 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:29:34 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24154025984, 'free_bytes': 27681075200, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24154025984, 'free_bytes': 27681075200, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24154025984, 'free_bytes': 27681075200, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24154025984, 'free_bytes': 27681075200, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24154025984, 'free_bytes': 27681075200, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24154025984, 'free_bytes': 27681075200, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1709225, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1760859, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:29:34 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:29:44 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:29:44 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24154025984, 'free_bytes': 27681075200, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24154025984, 'free_bytes': 27681075200, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24154025984, 'free_bytes': 27681075200, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24154025984, 'free_bytes': 27681075200, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24154025984, 'free_bytes': 27681075200, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24154025984, 'free_bytes': 27681075200, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1709225, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1760859, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:29:44 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:29:54 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:29:54 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24154025984, 'free_bytes': 27681075200, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24154025984, 'free_bytes': 27681075200, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24154025984, 'free_bytes': 27681075200, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24154025984, 'free_bytes': 27681075200, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24154025984, 'free_bytes': 27681075200, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24154025984, 'free_bytes': 27681075200, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1709225, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1760859, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:29:54 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:30:04 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:04 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:30:04 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:04 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:04 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:30:04 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:04 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:04 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:30:04 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:04 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:04 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:30:04 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:04 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:04 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:04 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:30:04 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:04 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:04 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:30:05 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:30:05 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:05 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:05 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:30:05 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:05 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:05 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:30:05 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:30:05 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:05 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:05 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:30:05 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:05 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:05 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:30:05 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24158691328, 'free_bytes': 27676409856, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24158691328, 'free_bytes': 27676409856, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24158691328, 'free_bytes': 27676409856, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24158691328, 'free_bytes': 27676409856, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24158691328, 'free_bytes': 27676409856, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24158691328, 'free_bytes': 27676409856, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1732622, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1783770, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:30:05 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:30:15 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:30:15 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24158691328, 'free_bytes': 27676409856, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24158691328, 'free_bytes': 27676409856, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24158691328, 'free_bytes': 27676409856, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24158691328, 'free_bytes': 27676409856, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24158691328, 'free_bytes': 27676409856, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24158691328, 'free_bytes': 27676409856, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1732622, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1783770, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:30:15 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:30:25 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:30:25 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24163151872, 'free_bytes': 27671949312, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24163151872, 'free_bytes': 27671949312, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24163151872, 'free_bytes': 27671949312, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24163151872, 'free_bytes': 27671949312, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24163151872, 'free_bytes': 27671949312, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24163151872, 'free_bytes': 27671949312, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1747660, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1799910, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:30:25 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-1: 03:30:30 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET /_cluster/health?wait_for_status=green&timeout=1m HTTP/11" 408 463
unit-opensearch-1: 03:30:30 DEBUG unit.opensearch/1.juju-log Request GET to https://10.206.183.63:9200/_cluster/health?wait_for_status=green&timeout=1m with payload: None failed.(Attempts left: 1)
	Error: 408 Client Error: Request Timeout for url: https://10.206.183.63:9200/_cluster/health?wait_for_status=green&timeout=1m
unit-opensearch-1: 03:30:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:30:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:30:35 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:30:35 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24163151872, 'free_bytes': 27671949312, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24163151872, 'free_bytes': 27671949312, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24163151872, 'free_bytes': 27671949312, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24163151872, 'free_bytes': 27671949312, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24163151872, 'free_bytes': 27671949312, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24163151872, 'free_bytes': 27671949312, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1747660, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1799910, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:30:35 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:30:45 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:30:45 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24163151872, 'free_bytes': 27671949312, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24163151872, 'free_bytes': 27671949312, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24163151872, 'free_bytes': 27671949312, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24163151872, 'free_bytes': 27671949312, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24163151872, 'free_bytes': 27671949312, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24163151872, 'free_bytes': 27671949312, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1747660, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1799910, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:30:45 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:30:55 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:55 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:30:55 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:55 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:55 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:30:55 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:55 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:30:56 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:30:56 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24168677376, 'free_bytes': 27666423808, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24168677376, 'free_bytes': 27666423808, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24168677376, 'free_bytes': 27666423808, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24168677376, 'free_bytes': 27666423808, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24168677376, 'free_bytes': 27666423808, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24168677376, 'free_bytes': 27666423808, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1763494, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1823242, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:30:56 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:31:06 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:31:06 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24168677376, 'free_bytes': 27666423808, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24168677376, 'free_bytes': 27666423808, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24168677376, 'free_bytes': 27666423808, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24168677376, 'free_bytes': 27666423808, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24168677376, 'free_bytes': 27666423808, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24168677376, 'free_bytes': 27666423808, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1763494, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1823242, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:31:06 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-self-signed-certificates-0: 03:31:11 DEBUG unit.self-signed-certificates/0.juju-log ops 2.14.0 up and running.
unit-self-signed-certificates-0: 03:31:11 DEBUG unit.self-signed-certificates/0.juju-log no relation on 'tracing': tracing not ready
unit-self-signed-certificates-0: 03:31:11 DEBUG unit.self-signed-certificates/0.juju-log Emitting Juju event update_status.
unit-self-signed-certificates-0: 03:31:11 INFO juju.worker.uniter.operation ran "update-status" hook (via hook dispatching script: dispatch)
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:31:16 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:31:16 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24168677376, 'free_bytes': 27666423808, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24168677376, 'free_bytes': 27666423808, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24168677376, 'free_bytes': 27666423808, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24168677376, 'free_bytes': 27666423808, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24168677376, 'free_bytes': 27666423808, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24168677376, 'free_bytes': 27666423808, 'free_disk_percent': 53.4, 'used_disk_percent': 46.6}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1763494, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1823242, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:31:16 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:31:26 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:31:26 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1786483, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1846295, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:31:26 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET /_cluster/health?wait_for_status=green&timeout=1m HTTP/11" 408 463
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-1: 03:31:31 INFO unit.opensearch/1.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}, 'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1786483, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1846295, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[.opensearch-observability][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[.opensearch-observability][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'shard_indexing_pressure_enabled': 'true', 'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-1: 03:31:31 INFO unit.opensearch/1.juju-log Current health of cluster: yellow-temp
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log self._app_workload_container_version='58' self._unit_workload_container_versions={'opensearch/2': '58', 'opensearch/1': '58', 'opensearch/0': '58'}
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Deferring <UpdateStatusEvent via OpenSearchOperatorCharm/on/update_status[450]>.
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log self._app_workload_container_version='58' self._unit_workload_container_versions={'opensearch/2': '58', 'opensearch/1': '58', 'opensearch/0': '58'}
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Re-emitting deferred event <UpdateStatusEvent via OpenSearchOperatorCharm/on/update_status[455]>.
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Executing command: sysctl -n vm.max_map_count
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log sysctl -n vm.max_map_count:
262144

unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Executing command: sysctl -n vm.swappiness
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log sysctl -n vm.swappiness:
0

unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Executing command: sysctl -n net.ipv4.tcp_retries2
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log sysctl -n net.ipv4.tcp_retries2:
5

unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET /_nodes HTTP/11" 200 53923
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET /_cluster/state/metadata/voting_config_exclusions HTTP/11" 200 454
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Current voting exclusions: {'opensearch-2.093'}
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log No voting exclusions to delete, current set is {'opensearch-2.093'}
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:31:31 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:31:36 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:31:37 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:31:37 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1786483, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1846295, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:31:37 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:31:47 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:31:47 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24190070784, 'free_bytes': 27645030400, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1786483, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1846295, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:31:47 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:31:57 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:31:57 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24195629056, 'free_bytes': 27639472128, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24195629056, 'free_bytes': 27639472128, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24195629056, 'free_bytes': 27639472128, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24195629056, 'free_bytes': 27639472128, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24195629056, 'free_bytes': 27639472128, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24195629056, 'free_bytes': 27639472128, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1809740, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1869566, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:31:57 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:32:07 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:32:07 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24195629056, 'free_bytes': 27639472128, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24195629056, 'free_bytes': 27639472128, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24195629056, 'free_bytes': 27639472128, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24195629056, 'free_bytes': 27639472128, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24195629056, 'free_bytes': 27639472128, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24195629056, 'free_bytes': 27639472128, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1809740, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1869566, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:32:07 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:32:17 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:17 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:32:17 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:17 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:17 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:32:17 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:17 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:17 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:32:17 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:17 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:17 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:32:17 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:17 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:18 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:18 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:32:18 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:18 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:18 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:32:18 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:32:18 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:18 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:18 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:32:18 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:18 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:18 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:32:18 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:32:18 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:18 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:18 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:32:18 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:18 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:18 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:32:18 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24195629056, 'free_bytes': 27639472128, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24195629056, 'free_bytes': 27639472128, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24195629056, 'free_bytes': 27639472128, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24195629056, 'free_bytes': 27639472128, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24195629056, 'free_bytes': 27639472128, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24195629056, 'free_bytes': 27639472128, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1809740, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1869566, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:32:18 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:32:28 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:32:28 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24201519104, 'free_bytes': 27633582080, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24201519104, 'free_bytes': 27633582080, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24201519104, 'free_bytes': 27633582080, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24201519104, 'free_bytes': 27633582080, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24201519104, 'free_bytes': 27633582080, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24201519104, 'free_bytes': 27633582080, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1833035, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1892467, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:32:28 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-1: 03:32:31 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET /_cluster/health?wait_for_status=green&timeout=1m HTTP/11" 408 463
unit-opensearch-1: 03:32:31 DEBUG unit.opensearch/1.juju-log Request GET to https://10.206.183.236:9200/_cluster/health?wait_for_status=green&timeout=1m with payload: None failed.(Attempts left: 2)
	Error: 408 Client Error: Request Timeout for url: https://10.206.183.236:9200/_cluster/health?wait_for_status=green&timeout=1m
unit-opensearch-1: 03:32:32 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:32:32 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:32:38 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:32:38 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24201519104, 'free_bytes': 27633582080, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24201519104, 'free_bytes': 27633582080, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24201519104, 'free_bytes': 27633582080, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24201519104, 'free_bytes': 27633582080, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24201519104, 'free_bytes': 27633582080, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24201519104, 'free_bytes': 27633582080, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1833035, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1892467, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:32:38 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:32:48 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:32:48 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24201519104, 'free_bytes': 27633582080, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24201519104, 'free_bytes': 27633582080, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24201519104, 'free_bytes': 27633582080, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24201519104, 'free_bytes': 27633582080, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24201519104, 'free_bytes': 27633582080, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24201519104, 'free_bytes': 27633582080, 'free_disk_percent': 53.3, 'used_disk_percent': 46.7}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1833035, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1892467, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.7gb], shard size: [208b], free after allocating shard: [25.7gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:32:48 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:32:58 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:32:58 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:32:59 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:32:59 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24240308224, 'free_bytes': 27594792960, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24240308224, 'free_bytes': 27594792960, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24240308224, 'free_bytes': 27594792960, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24240308224, 'free_bytes': 27594792960, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24240308224, 'free_bytes': 27594792960, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24240308224, 'free_bytes': 27594792960, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1857119, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1915428, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:32:59 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:33:09 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:33:09 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24240308224, 'free_bytes': 27594792960, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24240308224, 'free_bytes': 27594792960, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24240308224, 'free_bytes': 27594792960, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24240308224, 'free_bytes': 27594792960, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24240308224, 'free_bytes': 27594792960, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24240308224, 'free_bytes': 27594792960, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1857119, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1915428, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:33:09 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:33:19 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:33:19 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24240308224, 'free_bytes': 27594792960, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24240308224, 'free_bytes': 27594792960, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24240308224, 'free_bytes': 27594792960, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24240308224, 'free_bytes': 27594792960, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24240308224, 'free_bytes': 27594792960, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24240308224, 'free_bytes': 27594792960, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1857119, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1915428, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:33:19 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:33:29 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:33:29 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24263069696, 'free_bytes': 27572031488, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24263069696, 'free_bytes': 27572031488, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24263069696, 'free_bytes': 27572031488, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24263069696, 'free_bytes': 27572031488, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24263069696, 'free_bytes': 27572031488, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24263069696, 'free_bytes': 27572031488, 'free_disk_percent': 53.2, 'used_disk_percent': 46.8}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1872804, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1931125, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:33:29 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:33:29 ERROR unit.opensearch/2.juju-log Uncaught exception while in charm code:
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-opensearch-2/charm/./src/charm.py", line 213, in <module>
    main(OpenSearchOperatorCharm)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/main.py", line 553, in main
    manager.run()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/main.py", line 529, in run
    self._emit()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/main.py", line 515, in _emit
    self.framework.reemit()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/framework.py", line 863, in reemit
    self._reemit()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/framework.py", line 943, in _reemit
    custom_handler(event)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/lib/charms/opensearch/v0/opensearch_base_charm.py", line 1217, in _restart_opensearch
    self._stop_opensearch(restart=True)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/lib/charms/opensearch/v0/opensearch_base_charm.py", line 1202, in _stop_opensearch
    self.health.wait_for_shards_relocation()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/tenacity/__init__.py", line 336, in wrapped_f
    return copy(f, *args, **kw)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/lib/charms/opensearch/v0/opensearch_health.py", line 145, in wait_for_shards_relocation
    raise OpenSearchHAError("Shards haven't completed relocating.")
charms.opensearch.v0.opensearch_exceptions.OpenSearchHAError: Shards haven't completed relocating.
unit-opensearch-2: 03:33:29 ERROR juju.worker.uniter.operation hook "secret-changed" (via hook dispatching script: dispatch) failed: exit status 1
unit-opensearch-2: 03:33:29 INFO juju.worker.uniter awaiting error resolution for "secret-changed" hook
unit-opensearch-1: 03:33:32 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET /_cluster/health?wait_for_status=green&timeout=1m HTTP/11" 408 463
unit-opensearch-1: 03:33:32 DEBUG unit.opensearch/1.juju-log Request GET to https://10.206.183.63:9200/_cluster/health?wait_for_status=green&timeout=1m with payload: None failed.(Attempts left: 1)
	Error: 408 Client Error: Request Timeout for url: https://10.206.183.63:9200/_cluster/health?wait_for_status=green&timeout=1m
unit-opensearch-1: 03:33:33 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:33:33 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log ops 2.16.1 up and running.
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Re-emitting deferred event <_RestartOpenSearch via OpenSearchOperatorCharm/_restart_opensearch_event[298]>.
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log [Node lock] 1+ opensearch nodes online
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log https://10.206.183.236:9200 "GET /_nodes HTTP/11" 200 80467
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log [Node lock] Opensearch online_nodes=3
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:37 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log https://10.206.183.236:9200 "GET /.charm_node_lock/_source/0 HTTP/11" 200 33
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log [Node lock] Not acquired. Unit with opensearch lock: opensearch-2.093
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Lock to restart opensearch not acquired. Will retry next event
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Deferring <_RestartOpenSearch via OpenSearchOperatorCharm/_restart_opensearch_event[298]>.
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Re-emitting deferred event <CertificateAvailableEvent via OpenSearchOperatorCharm/TLSCertificatesRequiresV3[certificates]/on/certificate_available[299]>.
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log unit.unit-http TLS certificate available.
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log TLS CA rotation ongoing, will not update tls certificates.
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Deferring <CertificateAvailableEvent via OpenSearchOperatorCharm/TLSCertificatesRequiresV3[certificates]/on/certificate_available[299]>.
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Re-emitting deferred event <CertificateAvailableEvent via OpenSearchOperatorCharm/TLSCertificatesRequiresV3[certificates]/on/certificate_available[336]>.
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log unit.unit-transport TLS certificate available.
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log TLS CA rotation ongoing, will not update tls certificates.
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Deferring <CertificateAvailableEvent via OpenSearchOperatorCharm/TLSCertificatesRequiresV3[certificates]/on/certificate_available[336]>.
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Re-emitting deferred event <CertificateAvailableEvent via OpenSearchOperatorCharm/TLSCertificatesRequiresV3[certificates]/on/certificate_available[337]>.
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log unit.unit-http TLS certificate available.
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log TLS CA rotation ongoing, will not update tls certificates.
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Deferring <CertificateAvailableEvent via OpenSearchOperatorCharm/TLSCertificatesRequiresV3[certificates]/on/certificate_available[337]>.
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Re-emitting deferred event <CertificateAvailableEvent via OpenSearchOperatorCharm/TLSCertificatesRequiresV3[certificates]/on/certificate_available[354]>.
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log unit.unit-transport TLS certificate available.
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log TLS CA rotation ongoing, will not update tls certificates.
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Deferring <CertificateAvailableEvent via OpenSearchOperatorCharm/TLSCertificatesRequiresV3[certificates]/on/certificate_available[354]>.
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Re-emitting deferred event <CertificateAvailableEvent via OpenSearchOperatorCharm/TLSCertificatesRequiresV3[certificates]/on/certificate_available[355]>.
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log unit.unit-http TLS certificate available.
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log TLS CA rotation ongoing, will not update tls certificates.
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Deferring <CertificateAvailableEvent via OpenSearchOperatorCharm/TLSCertificatesRequiresV3[certificates]/on/certificate_available[355]>.
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Emitting Juju event update_status.
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Executing command: sysctl -n vm.max_map_count
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log sysctl -n vm.max_map_count:
262144

unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Executing command: sysctl -n vm.swappiness
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log sysctl -n vm.swappiness:
0

unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Executing command: sysctl -n net.ipv4.tcp_retries2
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log sysctl -n net.ipv4.tcp_retries2:
5

unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log https://10.206.183.63:9200 "GET /_nodes HTTP/11" 200 53923
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Getting secret app:admin-password
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log https://10.206.183.236:9200 "GET /_cluster/state/metadata/voting_config_exclusions HTTP/11" 200 454
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log Current voting exclusions: {'opensearch-2.093'}
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log No voting exclusions to delete, current set is {'opensearch-2.093'}
unit-opensearch-0: 03:33:38 DEBUG unit.opensearch/0.juju-log self._app_workload_container_version='58' self._unit_workload_container_versions={'opensearch/2': '58', 'opensearch/1': '58', 'opensearch/0': '58'}
unit-opensearch-0: 03:33:38 INFO juju.worker.uniter.operation ran "update-status" hook (via hook dispatching script: dispatch)
unit-opensearch-2: 03:33:50 INFO juju.worker.uniter awaiting error resolution for "secret-changed" hook
unit-opensearch-2: 03:33:50 DEBUG unit.opensearch/2.juju-log ops 2.16.1 up and running.
unit-opensearch-2: 03:33:50 DEBUG unit.opensearch/2.juju-log Re-emitting deferred event <_RestartOpenSearch via OpenSearchOperatorCharm/_restart_opensearch_event[275]>.
unit-opensearch-2: 03:33:50 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:50 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:50 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:33:50 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:50 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:33:50 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:50 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:50 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:33:50 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:50 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:50 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:33:50 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:50 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:50 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:33:50 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:50 DEBUG unit.opensearch/2.juju-log [Node lock] 1+ opensearch nodes online
unit-opensearch-2: 03:33:50 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:50 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_nodes HTTP/11" 200 53931
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log [Node lock] Opensearch online_nodes=2
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /.charm_node_lock/_source/0 HTTP/11" 200 33
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log [Node lock] Acquired via opensearch
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log [Node lock] Released redundant peer lock (if held)
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_nodes HTTP/11" 200 53931
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_nodes HTTP/11" 200 53931
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_nodes/UNGt6EEYRqCAB3pZdrWuMw HTTP/11" 200 26886
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "POST /_cluster/voting_config_exclusions?node_names=opensearch-2.093&timeout=1m HTTP/11" 200 0
unit-opensearch-2: 03:33:51 DEBUG unit.opensearch/2.juju-log Added voting, response: 200
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:33:56 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:33:56 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24287502336, 'free_bytes': 27547598848, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24287502336, 'free_bytes': 27547598848, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24287502336, 'free_bytes': 27547598848, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24287502336, 'free_bytes': 27547598848, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24287502336, 'free_bytes': 27547598848, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24287502336, 'free_bytes': 27547598848, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1895774, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1946887, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:33:56 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:34:06 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:06 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:07 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:34:07 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:34:07 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:07 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:07 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:34:07 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:07 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:07 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:34:07 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24287502336, 'free_bytes': 27547598848, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24287502336, 'free_bytes': 27547598848, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24287502336, 'free_bytes': 27547598848, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24287502336, 'free_bytes': 27547598848, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24287502336, 'free_bytes': 27547598848, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24287502336, 'free_bytes': 27547598848, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1895774, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1946887, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:34:07 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:34:17 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:34:17 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24287502336, 'free_bytes': 27547598848, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24287502336, 'free_bytes': 27547598848, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24287502336, 'free_bytes': 27547598848, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24287502336, 'free_bytes': 27547598848, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24287502336, 'free_bytes': 27547598848, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24287502336, 'free_bytes': 27547598848, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1895774, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1946887, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:34:17 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:34:27 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:34:27 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1911551, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1969658, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:34:27 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-1: 03:34:33 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET /_cluster/health?wait_for_status=green&timeout=1m HTTP/11" 408 463
unit-opensearch-1: 03:34:33 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:33 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:34:33 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:33 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:33 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:34:33 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:34:33 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:33 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:34:33 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:34:33 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:33 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:34:33 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-1: 03:34:34 INFO unit.opensearch/1.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1911551, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1969658, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[.opensearch-observability][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[.opensearch-observability][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'shard_indexing_pressure_enabled': 'true', 'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-1: 03:34:34 INFO unit.opensearch/1.juju-log Current health of cluster: yellow-temp
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log self._app_workload_container_version='58' self._unit_workload_container_versions={'opensearch/2': '58', 'opensearch/1': '58', 'opensearch/0': '58'}
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Deferring <UpdateStatusEvent via OpenSearchOperatorCharm/on/update_status[455]>.
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log self._app_workload_container_version='58' self._unit_workload_container_versions={'opensearch/2': '58', 'opensearch/1': '58', 'opensearch/0': '58'}
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Emitting Juju event update_status.
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Executing command: sysctl -n vm.max_map_count
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log sysctl -n vm.max_map_count:
262144

unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Executing command: sysctl -n vm.swappiness
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log sysctl -n vm.swappiness:
0

unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Executing command: sysctl -n net.ipv4.tcp_retries2
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log sysctl -n net.ipv4.tcp_retries2:
5

unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET /_nodes HTTP/11" 200 53923
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET /_cluster/state/metadata/voting_config_exclusions HTTP/11" 200 454
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Current voting exclusions: {'opensearch-2.093'}
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log No voting exclusions to delete, current set is {'opensearch-2.093'}
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:34:34 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:34:37 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:34:37 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1911551, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1969658, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:34:37 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:34:47 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:47 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:34:47 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:47 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:47 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:34:47 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:47 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:47 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:34:47 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:47 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:47 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:34:47 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:47 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:47 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:47 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:34:47 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:47 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:47 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:34:47 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:34:47 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:47 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:47 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:34:47 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:48 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:48 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:34:48 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:34:48 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:48 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:48 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:34:48 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:48 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:48 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:34:48 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24301879296, 'free_bytes': 27533221888, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1911551, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1969658, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:34:48 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:34:58 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:34:58 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24316317696, 'free_bytes': 27518783488, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24316317696, 'free_bytes': 27518783488, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24316317696, 'free_bytes': 27518783488, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24316317696, 'free_bytes': 27518783488, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24316317696, 'free_bytes': 27518783488, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24316317696, 'free_bytes': 27518783488, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1934337, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1992405, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:34:58 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:35:08 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:35:08 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24316317696, 'free_bytes': 27518783488, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24316317696, 'free_bytes': 27518783488, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24316317696, 'free_bytes': 27518783488, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24316317696, 'free_bytes': 27518783488, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24316317696, 'free_bytes': 27518783488, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24316317696, 'free_bytes': 27518783488, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1934337, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1992405, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:35:08 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:35:18 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:35:18 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24316317696, 'free_bytes': 27518783488, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24316317696, 'free_bytes': 27518783488, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24316317696, 'free_bytes': 27518783488, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24316317696, 'free_bytes': 27518783488, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24316317696, 'free_bytes': 27518783488, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24316317696, 'free_bytes': 27518783488, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1934337, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 1992405, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:35:18 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-self-signed-certificates-0: 03:35:24 DEBUG unit.self-signed-certificates/0.juju-log ops 2.14.0 up and running.
unit-self-signed-certificates-0: 03:35:24 DEBUG unit.self-signed-certificates/0.juju-log no relation on 'tracing': tracing not ready
unit-self-signed-certificates-0: 03:35:24 DEBUG unit.self-signed-certificates/0.juju-log Emitting Juju event update_status.
unit-self-signed-certificates-0: 03:35:24 INFO juju.worker.uniter.operation ran "update-status" hook (via hook dispatching script: dispatch)
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:35:28 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:28 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:29 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:35:29 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24322277376, 'free_bytes': 27512823808, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24322277376, 'free_bytes': 27512823808, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24322277376, 'free_bytes': 27512823808, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24322277376, 'free_bytes': 27512823808, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24322277376, 'free_bytes': 27512823808, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24322277376, 'free_bytes': 27512823808, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1957153, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 2015663, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:35:29 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-1: 03:35:34 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET /_cluster/health?wait_for_status=green&timeout=1m HTTP/11" 408 463
unit-opensearch-1: 03:35:34 DEBUG unit.opensearch/1.juju-log Request GET to https://10.206.183.236:9200/_cluster/health?wait_for_status=green&timeout=1m with payload: None failed.(Attempts left: 2)
	Error: 408 Client Error: Request Timeout for url: https://10.206.183.236:9200/_cluster/health?wait_for_status=green&timeout=1m
unit-opensearch-1: 03:35:35 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:35:35 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:35:39 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:35:39 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24322277376, 'free_bytes': 27512823808, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24322277376, 'free_bytes': 27512823808, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24322277376, 'free_bytes': 27512823808, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24322277376, 'free_bytes': 27512823808, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24322277376, 'free_bytes': 27512823808, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24322277376, 'free_bytes': 27512823808, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1957153, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 2015663, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:35:39 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:35:49 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:35:49 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24322277376, 'free_bytes': 27512823808, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24322277376, 'free_bytes': 27512823808, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24322277376, 'free_bytes': 27512823808, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24322277376, 'free_bytes': 27512823808, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24322277376, 'free_bytes': 27512823808, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24322277376, 'free_bytes': 27512823808, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1957153, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 2015663, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:35:49 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:35:59 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:35:59 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24335319040, 'free_bytes': 27499782144, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24335319040, 'free_bytes': 27499782144, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24335319040, 'free_bytes': 27499782144, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24335319040, 'free_bytes': 27499782144, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24335319040, 'free_bytes': 27499782144, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24335319040, 'free_bytes': 27499782144, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1973181, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 2030868, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:35:59 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:36:09 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:36:09 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24335319040, 'free_bytes': 27499782144, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24335319040, 'free_bytes': 27499782144, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24335319040, 'free_bytes': 27499782144, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24335319040, 'free_bytes': 27499782144, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24335319040, 'free_bytes': 27499782144, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24335319040, 'free_bytes': 27499782144, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1973181, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 2030868, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:36:09 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:36:19 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:19 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:36:19 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:36:19 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:19 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:36:19 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:36:19 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:19 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:36:19 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:36:19 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:19 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:36:19 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:36:19 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:19 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:19 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:36:19 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:19 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:19 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:36:19 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:36:19 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:20 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:20 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:36:20 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:20 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:20 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:36:20 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:36:20 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:20 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:20 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:36:20 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:20 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:20 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:36:20 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24335319040, 'free_bytes': 27499782144, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24335319040, 'free_bytes': 27499782144, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24335319040, 'free_bytes': 27499782144, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24335319040, 'free_bytes': 27499782144, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24335319040, 'free_bytes': 27499782144, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24335319040, 'free_bytes': 27499782144, 'free_disk_percent': 53.1, 'used_disk_percent': 46.9}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1973181, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 2030868, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.6gb], shard size: [208b], free after allocating shard: [25.6gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:36:20 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:36:30 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:36:30 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24348737536, 'free_bytes': 27486363648, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24348737536, 'free_bytes': 27486363648, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24348737536, 'free_bytes': 27486363648, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24348737536, 'free_bytes': 27486363648, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24348737536, 'free_bytes': 27486363648, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24348737536, 'free_bytes': 27486363648, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1996545, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 2053848, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:36:30 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-1: 03:36:35 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET /_cluster/health?wait_for_status=green&timeout=1m HTTP/11" 408 463
unit-opensearch-1: 03:36:35 DEBUG unit.opensearch/1.juju-log Request GET to https://10.206.183.63:9200/_cluster/health?wait_for_status=green&timeout=1m with payload: None failed.(Attempts left: 1)
	Error: 408 Client Error: Request Timeout for url: https://10.206.183.63:9200/_cluster/health?wait_for_status=green&timeout=1m
unit-opensearch-1: 03:36:36 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:36:36 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:36:40 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:36:40 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24348737536, 'free_bytes': 27486363648, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24348737536, 'free_bytes': 27486363648, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24348737536, 'free_bytes': 27486363648, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24348737536, 'free_bytes': 27486363648, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24348737536, 'free_bytes': 27486363648, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24348737536, 'free_bytes': 27486363648, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1996545, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 2053848, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:36:40 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:36:50 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:36:50 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24348737536, 'free_bytes': 27486363648, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24348737536, 'free_bytes': 27486363648, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24348737536, 'free_bytes': 27486363648, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24348737536, 'free_bytes': 27486363648, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24348737536, 'free_bytes': 27486363648, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24348737536, 'free_bytes': 27486363648, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 1996545, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 2053848, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:36:50 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:37:00 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:37:00 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24354611200, 'free_bytes': 27480489984, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24354611200, 'free_bytes': 27480489984, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24354607104, 'free_bytes': 27480494080, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24354607104, 'free_bytes': 27480494080, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24354611200, 'free_bytes': 27480489984, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24354611200, 'free_bytes': 27480489984, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 2019571, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 2077541, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:37:00 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:37:11 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:37:11 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24354611200, 'free_bytes': 27480489984, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24354611200, 'free_bytes': 27480489984, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24354607104, 'free_bytes': 27480494080, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24354607104, 'free_bytes': 27480494080, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24354611200, 'free_bytes': 27480489984, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24354611200, 'free_bytes': 27480489984, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 2019571, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 2077541, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:37:11 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:37:21 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:37:21 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24354611200, 'free_bytes': 27480489984, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24354611200, 'free_bytes': 27480489984, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24354607104, 'free_bytes': 27480494080, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24354607104, 'free_bytes': 27480494080, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24354611200, 'free_bytes': 27480489984, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24354611200, 'free_bytes': 27480489984, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 2019571, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 2077541, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:37:21 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:37:31 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:37:31 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 2042291, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 2100925, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:37:31 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-1: 03:37:36 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET /_cluster/health?wait_for_status=green&timeout=1m HTTP/11" 408 463
unit-opensearch-1: 03:37:36 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:36 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:37:36 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:37:36 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:36 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:37:36 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:37:36 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:36 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:37:36 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:36 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:36 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-1: 03:37:37 INFO unit.opensearch/1.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 2042291, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 2100925, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[.opensearch-observability][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[.opensearch-observability][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'shard_indexing_pressure_enabled': 'true', 'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-1: 03:37:37 INFO unit.opensearch/1.juju-log Current health of cluster: yellow-temp
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log self._app_workload_container_version='58' self._unit_workload_container_versions={'opensearch/2': '58', 'opensearch/1': '58', 'opensearch/0': '58'}
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Deferring <UpdateStatusEvent via OpenSearchOperatorCharm/on/update_status[460]>.
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log self._app_workload_container_version='58' self._unit_workload_container_versions={'opensearch/2': '58', 'opensearch/1': '58', 'opensearch/0': '58'}
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:37 INFO juju.worker.uniter.operation ran "update-status" hook (via hook dispatching script: dispatch)
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log ops 2.16.1 up and running.
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Re-emitting deferred event <CertificateAvailableEvent via OpenSearchOperatorCharm/TLSCertificatesRequiresV3[certificates]/on/certificate_available[428]>.
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log app.app-admin TLS certificate available.
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log TLS CA rotation not complete for unit <ops.model.Unit opensearch/0>.
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log TLS CA rotation ongoing, will not update tls certificates.
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Deferring <CertificateAvailableEvent via OpenSearchOperatorCharm/TLSCertificatesRequiresV3[certificates]/on/certificate_available[428]>.
unit-opensearch-1: 03:37:37 DEBUG unit.opensearch/1.juju-log Re-emitting deferred event <CertificateAvailableEvent via OpenSearchOperatorCharm/TLSCertificatesRequiresV3[certificates]/on/certificate_available[429]>.
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log unit.unit-http TLS certificate available.
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log TLS CA rotation not complete for unit <ops.model.Unit opensearch/0>.
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log TLS CA rotation ongoing, will not update tls certificates.
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Deferring <CertificateAvailableEvent via OpenSearchOperatorCharm/TLSCertificatesRequiresV3[certificates]/on/certificate_available[429]>.
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Re-emitting deferred event <CertificateAvailableEvent via OpenSearchOperatorCharm/TLSCertificatesRequiresV3[certificates]/on/certificate_available[430]>.
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log unit.unit-transport TLS certificate available.
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log TLS CA rotation not complete for unit <ops.model.Unit opensearch/0>.
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log TLS CA rotation ongoing, will not update tls certificates.
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Deferring <CertificateAvailableEvent via OpenSearchOperatorCharm/TLSCertificatesRequiresV3[certificates]/on/certificate_available[430]>.
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Re-emitting deferred event <UpdateStatusEvent via OpenSearchOperatorCharm/on/update_status[445]>.
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Executing command: sysctl -n vm.max_map_count
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log sysctl -n vm.max_map_count:
262144

unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Executing command: sysctl -n vm.swappiness
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log sysctl -n vm.swappiness:
0

unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Executing command: sysctl -n net.ipv4.tcp_retries2
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log sysctl -n net.ipv4.tcp_retries2:
5

unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET /_nodes HTTP/11" 200 80467
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET /_cluster/state/metadata/voting_config_exclusions HTTP/11" 200 454
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Current voting exclusions: {'opensearch-2.093'}
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log No voting exclusions to delete, current set is {'opensearch-2.093'}
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Error when checking if host 10.206.183.106 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log https://10.206.183.236:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET / HTTP/11" 200 573
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:37:38 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:37:41 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:37:41 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 2042291, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 2100925, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:37:41 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:37:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:37:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:37:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:37:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:51 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:51 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:37:51 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:37:52 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:52 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:52 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:37:52 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:52 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:52 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:37:52 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:37:52 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:52 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:52 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:37:52 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:52 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:52 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:37:52 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:37:52 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:52 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:52 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:37:52 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:37:52 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:37:52 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:37:52 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24360165376, 'free_bytes': 27474935808, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 2042291, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 2100925, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:37:52 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:38:02 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:38:02 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24374030336, 'free_bytes': 27461070848, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24374030336, 'free_bytes': 27461070848, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24374030336, 'free_bytes': 27461070848, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24374030336, 'free_bytes': 27461070848, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24374030336, 'free_bytes': 27461070848, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24374030336, 'free_bytes': 27461070848, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 2065395, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 2123736, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:38:02 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:38:12 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:38:12 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24374030336, 'free_bytes': 27461070848, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24374030336, 'free_bytes': 27461070848, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24374030336, 'free_bytes': 27461070848, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24374030336, 'free_bytes': 27461070848, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24374030336, 'free_bytes': 27461070848, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24374030336, 'free_bytes': 27461070848, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 2065395, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 2123736, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:38:12 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:38:22 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:38:22 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24374030336, 'free_bytes': 27461070848, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24374030336, 'free_bytes': 27461070848, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24374030336, 'free_bytes': 27461070848, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24374030336, 'free_bytes': 27461070848, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24374030336, 'free_bytes': 27461070848, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24374030336, 'free_bytes': 27461070848, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 2065395, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 2123736, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:38:22 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:38:32 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:32 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:33 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:38:33 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24379170816, 'free_bytes': 27455930368, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24379170816, 'free_bytes': 27455930368, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24379154432, 'free_bytes': 27455946752, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24379154432, 'free_bytes': 27455946752, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24379179008, 'free_bytes': 27455922176, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24379179008, 'free_bytes': 27455922176, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 2080491, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 2131810, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:38:33 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.
unit-opensearch-1: 03:38:38 DEBUG unit.opensearch/1.juju-log https://10.206.183.63:9200 "GET /_cluster/health?wait_for_status=green&timeout=1m HTTP/11" 408 463
unit-opensearch-1: 03:38:38 DEBUG unit.opensearch/1.juju-log Request GET to https://10.206.183.63:9200/_cluster/health?wait_for_status=green&timeout=1m with payload: None failed.(Attempts left: 2)
	Error: 408 Client Error: Request Timeout for url: https://10.206.183.63:9200/_cluster/health?wait_for_status=green&timeout=1m
unit-opensearch-1: 03:38:39 DEBUG unit.opensearch/1.juju-log Getting secret app:admin-password
unit-opensearch-1: 03:38:39 DEBUG unit.opensearch/1.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.63:9200
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.63 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.63', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.236:9200
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Error when checking if host 10.206.183.236 is up: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.236', port=9200): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/health HTTP/11" 200 464
unit-opensearch-2: 03:38:43 INFO unit.opensearch/2.juju-log Health: {'cluster_name': 'opensearch-2fvc', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 3, 'number_of_data_nodes': 3, 'discovered_master': True, 'discovered_cluster_manager': True, 'active_primary_shards': 6, 'active_shards': 12, 'relocating_shards': 0, 'initializing_shards': 2, 'unassigned_shards': 3, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 70.58823529411765}
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/state/routing_table,metadata,nodes HTTP/11" 200 11883
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log 

Health: yellow -- Shards: [{'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-observability', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.plugins-ml-config', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': 'series_index', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': 'series_index', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opensearch-sap-log-types-config', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.opendistro_security', 'shard': '0', 'prirep': 'r', 'state': 'INITIALIZING', 'ip': '10.206.183.106', 'node': 'opensearch-2.093', 'unassigned.reason': 'REPLICA_ADDED'}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'STARTED', 'ip': '10.206.183.236', 'node': 'opensearch-1.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'p', 'state': 'STARTED', 'ip': '10.206.183.63', 'node': 'opensearch-0.093', 'unassigned.reason': None}, {'index': '.charm_node_lock', 'shard': '0', 'prirep': 'r', 'state': 'UNASSIGNED', 'ip': None, 'node': None, 'unassigned.reason': 'REPLICA_ADDED'}]


unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET / HTTP/11" 200 573
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Getting secret app:admin-password
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Starting new HTTPS connection (1): 10.206.183.106:9200
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log https://10.206.183.106:9200 "GET /_cluster/allocation/explain?include_disk_info=true&include_yes_decisions=true HTTP/11" 200 13954
unit-opensearch-2: 03:38:43 DEBUG unit.opensearch/2.juju-log Allocation explanations: {'index': '.opensearch-observability', 'shard': 0, 'primary': False, 'current_state': 'unassigned', 'unassigned_info': {'reason': 'REPLICA_ADDED', 'at': '2024-10-08T03:02:15.684Z', 'last_allocation_status': 'no_attempt'}, 'cluster_info': {'nodes': {'UNGt6EEYRqCAB3pZdrWuMw': {'node_name': 'opensearch-2.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24379170816, 'free_bytes': 27455930368, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24379170816, 'free_bytes': 27455930368, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'SpzKMP7MSKaYqWKNXY36iQ': {'node_name': 'opensearch-1.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24379154432, 'free_bytes': 27455946752, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24379154432, 'free_bytes': 27455946752, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}, 'BNcHsyNyT5eDXQIcn386rw': {'node_name': 'opensearch-0.093', 'least_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24379179008, 'free_bytes': 27455922176, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}, 'most_available': {'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total_bytes': 51835101184, 'used_bytes': 24379179008, 'free_bytes': 27455922176, 'free_disk_percent': 53.0, 'used_disk_percent': 47.0}}}, 'shard_sizes': {'[.charm_node_lock][0][p]_bytes': 20367, '[series_index][0][r]_bytes': 2080491, '[.plugins-ml-config][0][r]_bytes': 4030, '[.opendistro_security][0][p]_bytes': 54959, '[.plugins-ml-config][0][p]_bytes': 4030, '[.opendistro_security][0][r]_bytes': 54959, '[.opensearch-observability][0][r]_bytes': 208, '[.opensearch-sap-log-types-config][0][r]_bytes': 136253, '[.opensearch-observability][0][p]_bytes': 208, '[series_index][0][p]_bytes': 2131810, '[.charm_node_lock][0][r]_bytes': 7225, '[.opensearch-sap-log-types-config][0][p]_bytes': 255460}, 'shard_paths': {'[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=qjFSOjisT-yEng69FBER5Q], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[4030]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[UNGt6EEYRqCAB3pZdrWuMw], [R], recovery_source[peer recovery], s[INITIALIZING], a[id=dhJxwzOyRkCknU7k0mysdg], unassigned_info[[reason=REPLICA_ADDED], at[2024-10-08T03:02:15.684Z], delayed=false, allocation_status[no_attempt]], expected_shard_size[54959]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=OCzRZ-0nTTOH0fYQEmd9KQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=C8ORsIBcQtuZey0PLlCWOQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.plugins-ml-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=M-Te65x5QxeNSYTahNEqqg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=fASGPO_rSjOSa3vVUd-grg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opensearch-sap-log-types-config][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=GRswx2B2TvqjNHXVtCPISA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.charm_node_lock][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=6LUrfTyJTNGlQKds1yAWOw]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=-1-uhdVCRyGnP0NGN12LuA]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=j4wd9hmIRDaVZy3LqdEQZg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[.opendistro_security][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=PT_cNIexTUmz6jwIZPjcrg]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', '[series_index][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=KSFBjSd4TBmTPr6L6k8ahQ]': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0'}, 'reserved_sizes': [{'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'path': '/var/snap/opensearch/common/var/lib/opensearch/nodes/0', 'total': 0, 'shards': ['[.plugins-ml-config][0]', '[.opensearch-observability][0]', '[.opendistro_security][0]', '[.charm_node_lock][0]', '[series_index][0]', '[.opensearch-sap-log-types-config][0]']}]}, 'can_allocate': 'throttled', 'allocate_explanation': 'allocation temporarily throttled', 'node_allocation_decisions': [{'node_id': 'UNGt6EEYRqCAB3pZdrWuMw', 'node_name': 'opensearch-2.093', 'transport_address': '10.206.183.106:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'throttled', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'YES', 'explanation': 'this node does not hold a copy of this shard'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'BNcHsyNyT5eDXQIcn386rw', 'node_name': 'opensearch-0.093', 'transport_address': '10.206.183.63:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 208}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[BNcHsyNyT5eDXQIcn386rw], [P], s[STARTED], a[id=ccXZgPe7RJ6xMNciSwK0yA]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}, {'node_id': 'SpzKMP7MSKaYqWKNXY36iQ', 'node_name': 'opensearch-1.093', 'transport_address': '10.206.183.236:9300', 'node_attributes': {'app_id': 'aa3120b8-573a-413e-8832-776ebd335105/opensearch', 'shard_indexing_pressure_enabled': 'true'}, 'node_decision': 'no', 'store': {'matching_size_in_bytes': 0}, 'deciders': [{'decider': 'max_retry', 'decision': 'YES', 'explanation': 'shard has no previous failures'}, {'decider': 'replica_after_primary_active', 'decision': 'YES', 'explanation': 'primary shard for this replica is already active'}, {'decider': 'cluster_concurrent_recoveries', 'decision': 'YES', 'explanation': 'undefined cluster concurrent recoveries'}, {'decider': 'enable', 'decision': 'YES', 'explanation': 'all allocations are allowed'}, {'decider': 'node_version', 'decision': 'YES', 'explanation': 'can allocate replica shard to a node with version [2.17.0] since this is equal-or-newer than the primary version [2.17.0]'}, {'decider': 'snapshot_in_progress', 'decision': 'YES', 'explanation': 'the shard is not being snapshotted'}, {'decider': 'restore_in_progress', 'decision': 'YES', 'explanation': 'ignored as shard is not being recovered from a snapshot'}, {'decider': 'filter', 'decision': 'YES', 'explanation': 'node passes include/exclude/require filters'}, {'decider': 'same_shard', 'decision': 'NO', 'explanation': 'a copy of this shard is already allocated to this node [[.opensearch-observability][0], node[SpzKMP7MSKaYqWKNXY36iQ], [R], s[STARTED], a[id=PO98AUXcRnWhuTlnaNOqYQ]]'}, {'decider': 'disk_threshold', 'decision': 'YES', 'explanation': 'enough disk for shard on node, free: [25.5gb], shard size: [208b], free after allocating shard: [25.5gb]'}, {'decider': 'throttling', 'decision': 'THROTTLE', 'explanation': 'reached the limit of outgoing shard recoveries [2] on the node [BNcHsyNyT5eDXQIcn386rw] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])'}, {'decider': 'shards_limit', 'decision': 'YES', 'explanation': 'total shard limits are disabled: [index: -1, cluster: -1] <= 0'}, {'decider': 'awareness', 'decision': 'YES', 'explanation': 'allocation awareness is not enabled, set cluster setting [cluster.routing.allocation.awareness.attributes] to enable it'}, {'decider': 'load_awareness', 'decision': 'YES', 'explanation': 'overload awareness allocation is not enabled, set cluster setting [cluster.routing.allocation.load_awareness.skew_factor] and cluster setting [cluster.routing.allocation.load_awareness.provisioned_capacity] to enable it'}, {'decider': 'target_pool', 'decision': 'YES', 'explanation': 'Routing pools are compatible. Shard pool: [LOCAL_ONLY], node pool: [LOCAL_ONLY]'}, {'decider': 'remote_store_migration', 'decision': 'YES', 'explanation': '[none migration_direction]: replica shard copy can be allocated to a non-remote node for strict compatibility mode'}]}]}


unit-opensearch-2: 03:38:43 INFO unit.opensearch/2.juju-log Shards still moving before stopping Opensearch.

[31m[1mERROR   [0m integration.helpers_deployments:helpers_deployments.py:94
[32mINFO    [0m pytest_operator.plugin:plugin.py:862 Model status:

Model  Controller           Cloud/Region         Version  SLA          Timestamp
test   localhost-localhost  localhost/localhost  3.5.3    unsupported  03:38:53Z

App                       Version  Status       Scale  Charm                     Channel        Rev  Exposed  Message
opensearch                         maintenance      3  opensearch                                 0  no       Some shards are still initializing / relocating.
self-signed-certificates           active           1  self-signed-certificates  latest/stable  155  no       

Unit                         Workload     Agent      Machine  Public address  Ports     Message
opensearch/0                 maintenance  idle       0        10.206.183.63   9200/tcp  Applying new CA certificate...
opensearch/1*                maintenance  idle       1        10.206.183.236  9200/tcp  Waiting for TLS to be fully configured...
opensearch/2                 waiting      executing  2        10.206.183.106  9200/tcp  The OpenSearch service is stopping.
self-signed-certificates/0*  active       idle       3        10.206.183.166            

Machine  State    Address         Inst id        Base          AZ  Message
0        started  10.206.183.63   juju-335105-0  ubuntu@22.04      Running
1        started  10.206.183.236  juju-335105-1  ubuntu@22.04      Running
2        started  10.206.183.106  juju-335105-2  ubuntu@22.04      Running
3        started  10.206.183.166  juju-335105-3  ubuntu@22.04      Running

[32mINFO    [0m pytest_operator.plugin:plugin.py:868 Juju error logs:

machine-1: 02:50:07 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 02:50:07 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-opensearch-1: 02:50:07 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-0: 02:50:12 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-0: 02:50:12 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-opensearch-0: 02:50:12 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-2: 02:50:24 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 02:50:24 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-opensearch-2: 02:50:24 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-3: 02:50:26 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 02:50:26 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-self-signed-certificates-0: 02:50:26 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-opensearch-1: 02:56:21 ERROR unit.opensearch/1.juju-log certificates:3: err:  / out: keytool error: java.lang.Exception: Keystore file does not exist: /var/snap/opensearch/current/etc/opensearch/certificates/ca.p12

unit-opensearch-1: 02:56:26 ERROR unit.opensearch/1.juju-log certificates:3: Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:26 ERROR unit.opensearch/0.juju-log certificates:3: err:  / out: keytool error: java.lang.Exception: Keystore file does not exist: /var/snap/opensearch/current/etc/opensearch/certificates/ca.p12

unit-opensearch-1: 02:56:28 ERROR unit.opensearch/1.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-1: 02:56:29 ERROR unit.opensearch/1.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-1: 02:56:29 ERROR unit.opensearch/1.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:31 ERROR unit.opensearch/0.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:56:32 ERROR unit.opensearch/2.juju-log certificates:3: err:  / out: keytool error: java.lang.Exception: Keystore file does not exist: /var/snap/opensearch/current/etc/opensearch/certificates/ca.p12

unit-opensearch-1: 02:56:32 ERROR unit.opensearch/1.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:32 ERROR unit.opensearch/0.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:33 ERROR unit.opensearch/0.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:34 ERROR unit.opensearch/0.juju-log node-lock-fallback:2: Cannot connect to the OpenSearch server...
unit-opensearch-1: 02:56:35 ERROR unit.opensearch/1.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:35 ERROR unit.opensearch/0.juju-log node-lock-fallback:2: Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:36 ERROR unit.opensearch/0.juju-log opensearch-peers:1: Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:56:37 ERROR unit.opensearch/2.juju-log opensearch-peers:1: Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:37 ERROR unit.opensearch/0.juju-log certificates:3: Cannot connect to the OpenSearch server...
unit-opensearch-1: 02:56:38 ERROR unit.opensearch/1.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:56:38 ERROR unit.opensearch/2.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:39 ERROR unit.opensearch/0.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:56:39 ERROR unit.opensearch/2.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:56:40 ERROR unit.opensearch/2.juju-log certificates:3: Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:40 ERROR unit.opensearch/0.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-1: 02:56:41 ERROR unit.opensearch/1.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:41 ERROR unit.opensearch/0.juju-log node-lock-fallback:2: Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:42 ERROR unit.opensearch/0.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:56:42 ERROR unit.opensearch/2.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:43 ERROR unit.opensearch/0.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:56:43 ERROR unit.opensearch/2.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:44 ERROR unit.opensearch/0.juju-log opensearch-peers:1: Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:56:44 ERROR unit.opensearch/2.juju-log opensearch-peers:1: Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:56:45 ERROR unit.opensearch/2.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:45 ERROR unit.opensearch/0.juju-log node-lock-fallback:2: Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:56:46 ERROR unit.opensearch/2.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:47 ERROR unit.opensearch/0.juju-log node-lock-fallback:2: Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:56:47 ERROR unit.opensearch/2.juju-log upgrade-version-a:0: Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:48 ERROR unit.opensearch/0.juju-log opensearch-peers:1: Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:56:48 ERROR unit.opensearch/2.juju-log opensearch-peers:1: Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:49 ERROR unit.opensearch/0.juju-log opensearch-peers:1: Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:56:49 ERROR unit.opensearch/2.juju-log opensearch-peers:1: Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:50 ERROR unit.opensearch/0.juju-log opensearch-peers:1: Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:56:50 ERROR unit.opensearch/2.juju-log node-lock-fallback:2: Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:51 ERROR unit.opensearch/0.juju-log node-lock-fallback:2: Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:56:51 ERROR unit.opensearch/2.juju-log opensearch-peers:1: Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:56:52 ERROR unit.opensearch/2.juju-log node-lock-fallback:2: Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:53 ERROR unit.opensearch/0.juju-log node-lock-fallback:2: Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:56:53 ERROR unit.opensearch/2.juju-log node-lock-fallback:2: Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:56:54 ERROR unit.opensearch/2.juju-log opensearch-peers:1: Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:54 ERROR unit.opensearch/0.juju-log node-lock-fallback:2: Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:56:55 ERROR unit.opensearch/2.juju-log node-lock-fallback:2: Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:56 ERROR unit.opensearch/0.juju-log node-lock-fallback:2: Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:56:56 ERROR unit.opensearch/2.juju-log node-lock-fallback:2: Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:56:57 ERROR unit.opensearch/2.juju-log node-lock-fallback:2: Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:57 ERROR unit.opensearch/0.juju-log node-lock-fallback:2: Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:56:58 ERROR unit.opensearch/0.juju-log node-lock-fallback:2: Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:56:58 ERROR unit.opensearch/2.juju-log node-lock-fallback:2: Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:57:00 ERROR unit.opensearch/2.juju-log node-lock-fallback:2: Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:57:02 ERROR unit.opensearch/0.juju-log opensearch-peers:1: Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:57:03 ERROR unit.opensearch/0.juju-log upgrade-version-a:0: Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:57:04 ERROR unit.opensearch/0.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:57:05 ERROR unit.opensearch/0.juju-log opensearch-peers:1: Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:57:10 ERROR unit.opensearch/0.juju-log node-lock-fallback:2: Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:57:17 ERROR unit.opensearch/0.juju-log opensearch-peers:1: Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:57:19 ERROR unit.opensearch/0.juju-log opensearch-peers:1: Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:58:50 ERROR unit.opensearch/2.juju-log certificates:3: Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:58:50 ERROR unit.opensearch/2.juju-log certificates:3: Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:58:52 ERROR unit.opensearch/2.juju-log certificates:3: Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:59:23 ERROR unit.opensearch/2.juju-log certificates:3: Error reloading TLS certificates via API: HTTP error self.response_code=500
self.response_body={'error': {'root_cause': [{'type': 'i_o_exception', 'reason': 'OpenSearchSecurityException[Error while initializing HTTP SSL layer: java.lang.Exception: New Certs do not have valid Issuer DN, Subject DN or SAN.]; nested: Exception[New Certs do not have valid Issuer DN, Subject DN or SAN.];'}], 'type': 'i_o_exception', 'reason': 'OpenSearchSecurityException[Error while initializing HTTP SSL layer: java.lang.Exception: New Certs do not have valid Issuer DN, Subject DN or SAN.]; nested: Exception[New Certs do not have valid Issuer DN, Subject DN or SAN.];', 'caused_by': {'type': 'security_exception', 'reason': 'Error while initializing HTTP SSL layer: java.lang.Exception: New Certs do not have valid Issuer DN, Subject DN or SAN.', 'caused_by': {'type': 'exception', 'reason': 'New Certs do not have valid Issuer DN, Subject DN or SAN.'}}}, 'status': 500}
unit-opensearch-2: 02:59:23 ERROR unit.opensearch/2.juju-log certificates:3: Could not reload TLS certificates via API, will restart.
unit-opensearch-2: 02:59:27 ERROR unit.opensearch/2.juju-log Error reloading TLS certificates via API: HTTP error self.response_code=500
self.response_body={'error': {'root_cause': [{'type': 'i_o_exception', 'reason': 'OpenSearchSecurityException[Error while initializing HTTP SSL layer: java.lang.Exception: New Certs do not have valid Issuer DN, Subject DN or SAN.]; nested: Exception[New Certs do not have valid Issuer DN, Subject DN or SAN.];'}], 'type': 'i_o_exception', 'reason': 'OpenSearchSecurityException[Error while initializing HTTP SSL layer: java.lang.Exception: New Certs do not have valid Issuer DN, Subject DN or SAN.]; nested: Exception[New Certs do not have valid Issuer DN, Subject DN or SAN.];', 'caused_by': {'type': 'security_exception', 'reason': 'Error while initializing HTTP SSL layer: java.lang.Exception: New Certs do not have valid Issuer DN, Subject DN or SAN.', 'caused_by': {'type': 'exception', 'reason': 'New Certs do not have valid Issuer DN, Subject DN or SAN.'}}}, 'status': 500}
unit-opensearch-2: 02:59:27 ERROR unit.opensearch/2.juju-log Could not reload TLS certificates via API, will restart.
unit-opensearch-1: 02:59:28 ERROR unit.opensearch/1.juju-log opensearch-peers:1: Cannot connect to the OpenSearch server...
unit-opensearch-1: 02:59:28 ERROR unit.opensearch/1.juju-log opensearch-peers:1: Cannot connect to the OpenSearch server...
unit-opensearch-1: 03:00:29 ERROR unit.opensearch/1.juju-log opensearch-peers:1: Cannot connect to the OpenSearch server...
unit-opensearch-2: 03:01:00 ERROR unit.opensearch/2.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-2: 03:01:00 ERROR unit.opensearch/2.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-2: 03:02:02 ERROR unit.opensearch/2.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-2: 03:02:35 ERROR unit.opensearch/2.juju-log Uncaught exception while in charm code:
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-opensearch-2/charm/lib/charms/opensearch/v0/opensearch_base_charm.py", line 998, in _start_opensearch
    self.opensearch.start(
  File "/var/lib/juju/agents/unit-opensearch-2/charm/lib/charms/opensearch/v0/opensearch_distro.py", line 122, in start
    raise OpenSearchStartTimeoutError()
charms.opensearch.v0.opensearch_exceptions.OpenSearchStartTimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-opensearch-2/charm/lib/charms/opensearch/v0/opensearch_distro.py", line 318, in request
    resp = call(urls)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/lib/charms/opensearch/v0/opensearch_distro.py", line 256, in call
    for attempt in Retrying(
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/var/lib/juju/agents/unit-opensearch-2/charm/lib/charms/opensearch/v0/opensearch_distro.py", line 287, in call
    response = s.request(**request_kwargs)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/requests/adapters.py", line 713, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='10.206.183.106', port=9200): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-opensearch-2/charm/./src/charm.py", line 213, in <module>
    main(OpenSearchOperatorCharm)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/main.py", line 553, in main
    manager.run()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/main.py", line 529, in run
    self._emit()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/main.py", line 515, in _emit
    self.framework.reemit()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/framework.py", line 863, in reemit
    self._reemit()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/framework.py", line 943, in _reemit
    custom_handler(event)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/lib/charms/opensearch/v0/opensearch_base_charm.py", line 1227, in _restart_opensearch
    self._start_opensearch_event.emit()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/framework.py", line 347, in emit
    framework._emit(event)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/framework.py", line 853, in _emit
    self._reemit(event_path)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/framework.py", line 943, in _reemit
    custom_handler(event)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/lib/charms/opensearch/v0/opensearch_base_charm.py", line 1010, in _start_opensearch
    self.node_lock.release()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/lib/charms/opensearch/v0/opensearch_locking.py", line 426, in release
    self._opensearch.request(
  File "/var/lib/juju/agents/unit-opensearch-2/charm/lib/charms/opensearch/v0/opensearch_distro.py", line 329, in request
    raise OpenSearchHttpError(response_text=str(e))
charms.opensearch.v0.opensearch_exceptions.OpenSearchHttpError: HTTP error self.response_code=None
self.response_text="HTTPSConnectionPool(host='10.206.183.106', port=9200): Read timed out. (read timeout=5)"
unit-opensearch-2: 03:02:35 ERROR juju.worker.uniter.operation hook "secret-changed" (via hook dispatching script: dispatch) failed: exit status 1
unit-opensearch-2: 03:18:00 ERROR unit.opensearch/2.juju-log Uncaught exception while in charm code:
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-opensearch-2/charm/./src/charm.py", line 213, in <module>
    main(OpenSearchOperatorCharm)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/main.py", line 553, in main
    manager.run()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/main.py", line 529, in run
    self._emit()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/main.py", line 515, in _emit
    self.framework.reemit()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/framework.py", line 863, in reemit
    self._reemit()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/framework.py", line 943, in _reemit
    custom_handler(event)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/lib/charms/opensearch/v0/opensearch_base_charm.py", line 1217, in _restart_opensearch
    self._stop_opensearch(restart=True)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/lib/charms/opensearch/v0/opensearch_base_charm.py", line 1202, in _stop_opensearch
    self.health.wait_for_shards_relocation()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/tenacity/__init__.py", line 336, in wrapped_f
    return copy(f, *args, **kw)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/lib/charms/opensearch/v0/opensearch_health.py", line 145, in wait_for_shards_relocation
    raise OpenSearchHAError("Shards haven't completed relocating.")
charms.opensearch.v0.opensearch_exceptions.OpenSearchHAError: Shards haven't completed relocating.
unit-opensearch-2: 03:18:01 ERROR juju.worker.uniter.operation hook "secret-changed" (via hook dispatching script: dispatch) failed: exit status 1
unit-opensearch-2: 03:33:29 ERROR unit.opensearch/2.juju-log Uncaught exception while in charm code:
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-opensearch-2/charm/./src/charm.py", line 213, in <module>
    main(OpenSearchOperatorCharm)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/main.py", line 553, in main
    manager.run()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/main.py", line 529, in run
    self._emit()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/main.py", line 515, in _emit
    self.framework.reemit()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/framework.py", line 863, in reemit
    self._reemit()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/ops/framework.py", line 943, in _reemit
    custom_handler(event)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/lib/charms/opensearch/v0/opensearch_base_charm.py", line 1217, in _restart_opensearch
    self._stop_opensearch(restart=True)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/lib/charms/opensearch/v0/opensearch_base_charm.py", line 1202, in _stop_opensearch
    self.health.wait_for_shards_relocation()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/tenacity/__init__.py", line 336, in wrapped_f
    return copy(f, *args, **kw)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/var/lib/juju/agents/unit-opensearch-2/charm/venv/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
  File "/var/lib/juju/agents/unit-opensearch-2/charm/lib/charms/opensearch/v0/opensearch_health.py", line 145, in wait_for_shards_relocation
    raise OpenSearchHAError("Shards haven't completed relocating.")
charms.opensearch.v0.opensearch_exceptions.OpenSearchHAError: Shards haven't completed relocating.
unit-opensearch-2: 03:33:29 ERROR juju.worker.uniter.operation hook "secret-changed" (via hook dispatching script: dispatch) failed: exit status 1

[32mINFO    [0m pytest_operator.plugin:plugin.py:947 Forgetting model main...