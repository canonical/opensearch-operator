"groups":
- "name": "opensearch.alerts"
  "rules":
  - "alert": "OpenSearchClusterNotHealthy"
    "annotations":
      "message": "Cluster {{ $labels.cluster }} health status has been RED for at least 2m. Cluster does not accept writes, shards may be missing or master node hasn't been elected yet."
      "summary": "Cluster health status is RED"
    "expr": |
      sum by (cluster) (opensearch_cluster_status == 2)
    "for": "2m"
    "labels":
      "severity": "critical"
  - "alert": "OpenSearchClusterNotHealthy"
    "annotations":
      "message": "Cluster {{ $labels.cluster }} health status has been YELLOW for at least 20m. Some shard replicas are not allocated."
      "summary": "Cluster health status is YELLOW"
    "expr": |
      sum by (cluster) (opensearch_cluster_status == 1)
    "for": "20m"
    "labels":
      "severity": "warning"
  - "alert": "OpenSearchBulkRequestsRejectionJumps"
    "annotations":
      "message": "High Bulk Rejection Ratio at {{ $labels.node }} node in {{ $labels.cluster }} cluster. This node may not be keeping up with the indexing speed."
      "summary": "High Bulk Rejection Ratio - {{ $value }}%"
    "expr": |
      round( bulk:reject_ratio:rate2m * 100, 0.001 ) > 5
    "for": "10m"
    "labels":
      "severity": "warning"
  - "alert": "OpenSearchNodeDiskWatermarkReached"
    "annotations":
      "message": "Disk Low Watermark Reached at {{ $labels.node }} node in {{ $labels.cluster }} cluster. Shards can not be allocated to this node anymore. You should consider adding more disk to the node."
      "summary": "Disk Low Watermark Reached - disk saturation is {{ $value }}%"
    "expr": |
      sum by (cluster, instance, node) (
        round(
          (1 - (
            opensearch_fs_path_available_bytes /
            opensearch_fs_path_total_bytes
          )
        ) * 100, 0.001)
      ) > 85
    "for": "5m"
    "labels":
      "severity": "alert"
  - "alert": "OpenSearchNodeDiskWatermarkReached"
    "annotations":
      "message": "Disk High Watermark Reached at {{ $labels.node }} node in {{ $labels.cluster }} cluster. Some shards will be re-allocated to different nodes if possible. Make sure more disk space is added to the node or drop old indices allocated to this node."
      "summary": "Disk High Watermark Reached - disk saturation is {{ $value }}%"
    "expr": |
      sum by (cluster, instance, node) (
        round(
          (1 - (
            opensearch_fs_path_available_bytes /
            opensearch_fs_path_total_bytes
          )
        ) * 100, 0.001)
      ) > 90
    "for": "5m"
    "labels":
      "severity": "high"
  - "alert": "OpenSearchJVMHeapUseHigh"
    "annotations":
      "message": "JVM Heap usage on the node {{ $labels.node }} in {{ $labels.cluster }} cluster is {{ $value }}%."
      "summary": "JVM Heap usage on the node is high"
    "expr": |
      sum by (cluster, instance, node) (opensearch_jvm_mem_heap_used_percent) > 75
    "for": "10m"
    "labels":
      "severity": "alert"
  - "alert": "OpenSearchHostSystemCPUHigh"
    "annotations":
      "message": "System CPU usage on the node {{ $labels.node }} in {{ $labels.cluster }} cluster is {{ $value }}%"
      "summary": "System CPU usage is high"
    "expr": |
      sum by (cluster, instance, node) (opensearch_os_cpu_percent) > 90
    "for": "1m"
    "labels":
      "severity": "alert"
  - "alert": "OpenSearchProcessCPUHigh"
    "annotations":
      "message": "OSE process CPU usage on the node {{ $labels.node }} in {{ $labels.cluster }} cluster is {{ $value }}%"
      "summary": "OSE process CPU usage is high"
    "expr": |
      sum by (cluster, instance, node) (opensearch_process_cpu_percent) > 90
    "for": "1m"
    "labels":
      "severity": "alert"
