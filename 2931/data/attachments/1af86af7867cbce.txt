[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/3 [idle] active: 
  opensearch/4 [idle] active: 
  opensearch/5 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/3 [idle] active: 
  opensearch/4 [idle] active: 
  opensearch/5 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/3 [idle] active: 
  opensearch/4 [idle] active: 
  opensearch/5 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/5 [executing] maintenance: Installing OpenSearch...
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/5 [executing] maintenance: Installing OpenSearch...
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/5 [executing] maintenance: Installing OpenSearch...
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/5 [executing] maintenance: Installing OpenSearch...
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/5 [executing] maintenance: Installing OpenSearch...
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/5 [executing] maintenance: Installing OpenSearch...
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/5 [executing] maintenance: Installing OpenSearch...
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/5 [executing] maintenance: Installing OpenSearch...
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/5 [executing] maintenance: Installing OpenSearch...
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/3 [executing] active: 
  opensearch/4 [executing] active: 
  opensearch/5 [executing] maintenance: Waiting for TLS to be fully configured...
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/3 [idle] active: 
  opensearch/4 [idle] active: 
  opensearch/5 [executing] active: 
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/3 [idle] active: 
  opensearch/4 [idle] active: 
  opensearch/5 [idle] active: 
[32mINFO    [0m juju.model:model.py:2971 Waiting for model:
  opensearch/3 [idle] active: 
  opensearch/4 [idle] active: 
  opensearch/5 [idle] active: 
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:329 



[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:330 Model  Controller           Cloud/Region         Version  SLA          Timestamp
test   localhost-localhost  localhost/localhost  3.5.3    unsupported  02:44:23Z

App                       Version  Status   Scale  Charm                     Channel        Rev  Exposed  Message
opensearch                         waiting    0/1  opensearch                                 1  no       waiting for machine
self-signed-certificates           active       1  self-signed-certificates  latest/stable  155  no       

Unit                         Workload  Agent       Machine  Public address  Ports  Message
opensearch/6                 waiting   allocating  7                               waiting for machine
self-signed-certificates/0*  active    executing   0        10.107.212.167         

Machine  State    Address         Inst id        Base          AZ  Message
0        started  10.107.212.167  juju-a461f4-0  ubuntu@22.04      Running
7        pending                  pending        ubuntu@22.04      

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:44:23 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:251 opensearch -- expected units: 1 -- current: 0
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:44:33 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch waiting -- message: waiting for machine
		opensearch-6.dd7  -- (10.107.212.120) -- [allocating (since: 02:44:23)] waiting: waiting for machine

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:46:47 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch maintenance -- message: Waiting for TLS to be fully configured...
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:46:47)] maintenance: Waiting for TLS to be fully configured...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:46:58 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch waiting -- message: Waiting for OpenSearch to start...
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:46:50)] waiting: Waiting for OpenSearch to start...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:47:09 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:47:04)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:47:19 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:47:04)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:47:30 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:47:04)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:47:40 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:47:04)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:47:51 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:47:04)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:48:02 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:47:04)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:48:13 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:47:04)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:48:23 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:47:04)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:48:34 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:47:04)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:48:44 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:47:04)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:48:55 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:47:04)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:49:06 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:47:04)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:49:16 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:47:04)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:49:27 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:47:04)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:49:38 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:47:04)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:49:48 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:47:04)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:49:59 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:47:04)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:50:10 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:47:04)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:50:20 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:50:19)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:50:31 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [idle (since: 02:50:20)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:50:42 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [idle (since: 02:50:20)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:50:52 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [idle (since: 02:50:20)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:51:03 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [idle (since: 02:50:20)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:51:14 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [idle (since: 02:50:20)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:51:24 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [idle (since: 02:50:20)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:51:35 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:348 02:51:35 -- Waiting for model: complete.



[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:329 



[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:330 Model  Controller           Cloud/Region         Version  SLA          Timestamp
test   localhost-localhost  localhost/localhost  3.5.3    unsupported  02:51:36Z

App                       Version  Status   Scale  Charm                     Channel        Rev  Exposed  Message
opensearch                         blocked    1/3  opensearch                                 1  no       1 or more 'replica' shards are not assigned, please scale your application up.
self-signed-certificates           active       1  self-signed-certificates  latest/stable  155  no       

Unit                         Workload  Agent       Machine  Public address  Ports     Message
opensearch/6*                active    idle        7        10.107.212.120  9200/tcp  
opensearch/7                 waiting   allocating  8                                  waiting for machine
opensearch/8                 waiting   allocating  9                                  waiting for machine
self-signed-certificates/0*  active    idle        0        10.107.212.167            

Machine  State    Address         Inst id        Base          AZ  Message
0        started  10.107.212.167  juju-a461f4-0  ubuntu@22.04      Running
7        started  10.107.212.120  juju-a461f4-7  ubuntu@22.04      Running
8        pending                  pending        ubuntu@22.04      
9        pending                  pending        ubuntu@22.04      

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:51:36 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:251 opensearch -- expected units: 3 -- current: 1
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:51:46 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:251 opensearch -- expected units: 3 -- current: 1
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:51:57 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [idle (since: 02:50:20)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [allocating (since: 02:51:36)] waiting: waiting for machine
		opensearch-8.dd7  -- (10.107.212.82) -- [allocating (since: 02:51:36)] waiting: waiting for machine

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:53:13 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [idle (since: 02:50:20)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [executing (since: 02:53:05)] maintenance: Installing OpenSearch...
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:53:05)] maintenance: Installing OpenSearch...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:53:25 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [idle (since: 02:50:20)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [executing (since: 02:53:05)] maintenance: Installing OpenSearch...
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:53:05)] maintenance: Installing OpenSearch...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:53:36 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [idle (since: 02:50:20)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [executing (since: 02:53:05)] maintenance: Installing OpenSearch...
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:53:05)] maintenance: Installing OpenSearch...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:53:48 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [idle (since: 02:50:20)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [executing (since: 02:53:05)] maintenance: Installing OpenSearch...
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:53:05)] maintenance: Installing OpenSearch...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:53:59 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:53:50)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [executing (since: 02:53:05)] maintenance: Installing OpenSearch...
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:53:05)] maintenance: Installing OpenSearch...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:54:11 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:53:50)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [executing (since: 02:54:08)] active: 
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:54:11)] maintenance: Waiting for TLS to be fully configured...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:54:23 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:53:50)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [executing (since: 02:54:23)] maintenance: Waiting for TLS to be fully configured...
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:54:16)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:54:35 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:53:50)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [executing (since: 02:54:35)] maintenance: Waiting for TLS to be fully configured...
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:54:16)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:54:46 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:53:50)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [executing (since: 02:54:46)] waiting: Requesting lock on operation: start
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:54:16)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:54:58 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:53:50)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [idle (since: 02:54:47)] waiting: Requesting lock on operation: start
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:54:16)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:55:09 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:53:50)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [idle (since: 02:54:47)] waiting: Requesting lock on operation: start
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:54:16)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:55:21 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:53:50)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [idle (since: 02:54:47)] waiting: Requesting lock on operation: start
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:54:16)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:55:33 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:53:50)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [idle (since: 02:54:47)] waiting: Requesting lock on operation: start
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:54:16)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:55:45 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:53:50)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [idle (since: 02:54:47)] waiting: Requesting lock on operation: start
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:54:16)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:55:56 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:53:50)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [idle (since: 02:54:47)] waiting: Requesting lock on operation: start
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:54:16)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:56:08 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:53:50)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [idle (since: 02:54:47)] waiting: Requesting lock on operation: start
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:54:16)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:56:19 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:53:50)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [idle (since: 02:54:47)] waiting: Requesting lock on operation: start
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:54:16)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:56:31 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:53:50)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [idle (since: 02:54:47)] waiting: Requesting lock on operation: start
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:54:16)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:56:43 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:53:50)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [idle (since: 02:54:47)] waiting: Requesting lock on operation: start
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:54:16)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:56:54 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:56:54)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [idle (since: 02:54:47)] waiting: Requesting lock on operation: start
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:54:16)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:57:06 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:56:54)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [idle (since: 02:54:47)] waiting: Requesting lock on operation: start
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:54:16)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:57:17 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:56:54)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [idle (since: 02:54:47)] waiting: Requesting lock on operation: start
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:54:16)] waiting: Requesting lock on operation: start

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:57:29 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:261 	App: opensearch - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:262 
	app: opensearch blocked -- message: 1 or more 'replica' shards are not assigned, please scale your application up.
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:56:54)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [idle (since: 02:54:47)] waiting: Requesting lock on operation: start
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:54:16)] waiting: Waiting for OpenSearch to start...

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:57:40 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [executing (since: 02:57:40)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [executing (since: 02:57:35)] waiting: Waiting for OpenSearch to start...
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:57:40)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:57:53 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [idle (since: 02:57:49)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [executing (since: 02:57:35)] waiting: Waiting for OpenSearch to start...
		opensearch-8.dd7  -- (10.107.212.82) -- [executing (since: 02:57:53)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:58:04 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [idle (since: 02:58:01)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [idle (since: 02:58:01)] active: 
		opensearch-8.dd7  -- (10.107.212.82) -- [idle (since: 02:58:01)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:58:16 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [idle (since: 02:58:01)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [idle (since: 02:58:01)] active: 
		opensearch-8.dd7  -- (10.107.212.82) -- [idle (since: 02:58:01)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:58:27 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [idle (since: 02:58:01)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [idle (since: 02:58:01)] active: 
		opensearch-8.dd7  -- (10.107.212.82) -- [idle (since: 02:58:01)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:58:39 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [idle (since: 02:58:01)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [idle (since: 02:58:01)] active: 
		opensearch-8.dd7  -- (10.107.212.82) -- [idle (since: 02:58:01)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:58:50 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [idle (since: 02:58:01)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [idle (since: 02:58:01)] active: 
		opensearch-8.dd7  -- (10.107.212.82) -- [idle (since: 02:58:01)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:59:02 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [idle (since: 02:58:01)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [idle (since: 02:58:01)] active: 
		opensearch-8.dd7  -- (10.107.212.82) -- [idle (since: 02:58:01)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:59:14 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:277 	App: opensearch - Units - conditions unmet.
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:278 
	app: opensearch active -- message: None
		opensearch-6.dd7* -- (10.107.212.120) -- [idle (since: 02:58:01)] active: 
		opensearch-7.dd7  -- (10.107.212.59) -- [idle (since: 02:58:01)] active: 
		opensearch-8.dd7  -- (10.107.212.82) -- [idle (since: 02:58:01)] active: 

[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:337 


02:59:25 -- Waiting for model...
[32mINFO    [0m integration.helpers_deployments:helpers_deployments.py:348 02:59:27 -- Waiting for model: complete.
[32mINFO    [0m integration.ha.conftest:conftest.py:57 



The writes have been cleared.




[32mINFO    [0m pytest_operator.plugin:plugin.py:862 Model status:

Model  Controller           Cloud/Region         Version  SLA          Timestamp
test   localhost-localhost  localhost/localhost  3.5.3    unsupported  03:00:54Z

App                       Version  Status  Scale  Charm                     Channel        Rev  Exposed  Message
opensearch                         active      3  opensearch                                 1  no       
self-signed-certificates           active      1  self-signed-certificates  latest/stable  155  no       

Unit                         Workload  Agent  Machine  Public address  Ports     Message
opensearch/6*                active    idle   7        10.107.212.120  9200/tcp  
opensearch/7                 active    idle   8        10.107.212.59   9200/tcp  
opensearch/8                 active    idle   9        10.107.212.82   9200/tcp  
self-signed-certificates/0*  active    idle   0        10.107.212.167            

Machine  State    Address         Inst id        Base          AZ  Message
0        started  10.107.212.167  juju-a461f4-0  ubuntu@22.04      Running
7        started  10.107.212.120  juju-a461f4-7  ubuntu@22.04      Running
8        started  10.107.212.59   juju-a461f4-8  ubuntu@22.04      Running
9        started  10.107.212.82   juju-a461f4-9  ubuntu@22.04      Running

[32mINFO    [0m pytest_operator.plugin:plugin.py:868 Juju error logs:

machine-0: 01:54:14 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-0: 01:54:14 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-self-signed-certificates-0: 01:54:14 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-1: 01:54:16 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 01:54:16 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-opensearch-0: 01:54:16 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-opensearch-0: 01:56:21 ERROR unit.opensearch/0.juju-log certificates:3: err:  / out: keytool error: java.lang.Exception: Keystore file does not exist: /var/snap/opensearch/current/etc/opensearch/certificates/ca.p12

unit-opensearch-0: 01:56:27 ERROR unit.opensearch/0.juju-log certificates:3: Cannot connect to the OpenSearch server...
unit-opensearch-0: 01:56:27 ERROR unit.opensearch/0.juju-log certificates:3: Cannot connect to the OpenSearch server...
unit-opensearch-0: 01:56:27 ERROR unit.opensearch/0.juju-log certificates:3: Cannot connect to the OpenSearch server...
unit-opensearch-0: 01:56:30 ERROR unit.opensearch/0.juju-log certificates:3: Cannot connect to the OpenSearch server...
unit-opensearch-0: 01:56:33 ERROR unit.opensearch/0.juju-log certificates:3: Cannot connect to the OpenSearch server...
unit-opensearch-0: 01:56:36 ERROR unit.opensearch/0.juju-log certificates:3: Cannot connect to the OpenSearch server...
unit-opensearch-0: 01:56:39 ERROR unit.opensearch/0.juju-log certificates:3: Cannot connect to the OpenSearch server...
machine-2: 01:59:44 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 01:59:44 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-opensearch-1: 01:59:45 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-opensearch-1: 02:01:21 ERROR unit.opensearch/1.juju-log certificates:3: err:  / out: keytool error: java.lang.Exception: Keystore file does not exist: /var/snap/opensearch/current/etc/opensearch/certificates/ca.p12

unit-opensearch-1: 02:01:26 ERROR unit.opensearch/1.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-1: 02:04:29 ERROR unit.opensearch/1.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-1: 02:05:26 ERROR juju.worker.uniter resolver loop error: preparing operation "run storage-detaching (opensearch-data/1) hook" for opensearch/1: secret "secret:cs1k1pqo5e8hjftjdmt0" not found (not found)
unit-opensearch-1: 02:05:26 ERROR juju.worker.dependency "uniter" manifold worker returned unexpected error: preparing operation "run storage-detaching (opensearch-data/1) hook" for opensearch/1: secret "secret:cs1k1pqo5e8hjftjdmt0" not found (not found)
unit-opensearch-1: 02:05:37 ERROR unit.opensearch/1.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-1: 02:08:46 ERROR unit.opensearch/1.juju-log certificates:3: Error reading secret: 'NoneType' object has no attribute 'get'
machine-3: 02:11:21 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 02:11:21 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-opensearch-2: 02:11:21 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-opensearch-2: 02:12:29 ERROR unit.opensearch/2.juju-log certificates:3: err:  / out: keytool error: java.lang.Exception: Keystore file does not exist: /var/snap/opensearch/current/etc/opensearch/certificates/ca.p12

unit-opensearch-2: 02:12:43 ERROR unit.opensearch/2.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:16:08 ERROR unit.opensearch/2.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:18:59 ERROR unit.opensearch/2.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-0: 02:19:52 ERROR juju.worker.uniter resolver loop error: preparing operation "run storage-detaching (opensearch-data/0) hook" for opensearch/0: secret "secret:cs1jvhio5e8hjftjdmrg" not found (not found)
unit-opensearch-0: 02:19:52 ERROR juju.worker.dependency "uniter" manifold worker returned unexpected error: preparing operation "run storage-detaching (opensearch-data/0) hook" for opensearch/0: secret "secret:cs1jvhio5e8hjftjdmrg" not found (not found)
unit-opensearch-0: 02:20:02 ERROR unit.opensearch/0.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-2: 02:20:06 ERROR unit.opensearch/2.juju-log certificates:3: Error reading secret: 'NoneType' object has no attribute 'get'
unit-opensearch-0: 02:20:06 ERROR unit.opensearch/0.juju-log certificates:3: Error reading secret: 'NoneType' object has no attribute 'get'
machine-4: 02:22:19 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-4: 02:22:19 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-opensearch-3: 02:22:19 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-opensearch-3: 02:23:47 ERROR unit.opensearch/3.juju-log certificates:3: err:  / out: keytool error: java.lang.Exception: Keystore file does not exist: /var/snap/opensearch/current/etc/opensearch/certificates/ca.p12

unit-opensearch-3: 02:23:54 ERROR unit.opensearch/3.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-3: 02:23:55 ERROR unit.opensearch/3.juju-log Cannot connect to the OpenSearch server...
machine-5: 02:28:54 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-5: 02:28:54 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-opensearch-4: 02:28:54 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-opensearch-4: 02:30:01 ERROR unit.opensearch/4.juju-log certificates:3: err:  / out: keytool error: java.lang.Exception: Keystore file does not exist: /var/snap/opensearch/current/etc/opensearch/certificates/ca.p12

unit-opensearch-4: 02:30:05 ERROR unit.opensearch/4.juju-log opensearch-peers:2: Cannot connect to the OpenSearch server...
unit-opensearch-4: 02:33:09 ERROR unit.opensearch/4.juju-log opensearch-peers:2: Cannot connect to the OpenSearch server...
machine-6: 02:36:51 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-6: 02:36:51 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-opensearch-5: 02:36:51 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-opensearch-5: 02:41:35 ERROR unit.opensearch/5.juju-log certificates:3: err:  / out: keytool error: java.lang.Exception: Keystore file does not exist: /var/snap/opensearch/current/etc/opensearch/certificates/ca.p12

unit-opensearch-5: 02:41:40 ERROR unit.opensearch/5.juju-log opensearch-peers:2: Cannot connect to the OpenSearch server...
unit-opensearch-5: 02:41:41 ERROR unit.opensearch/5.juju-log opensearch-peers:2: Cannot connect to the OpenSearch server...
unit-opensearch-3: 02:43:43 ERROR juju.worker.uniter resolver loop error: preparing operation "run relation-departed (3; unit: self-signed-certificates/0, departee: opensearch/3) hook" for opensearch/3: secret "secret:cs1kcd2o5e8hjftjdn2g" not found (not found)
unit-opensearch-3: 02:43:43 ERROR juju.worker.dependency "uniter" manifold worker returned unexpected error: preparing operation "run relation-departed (3; unit: self-signed-certificates/0, departee: opensearch/3) hook" for opensearch/3: secret "secret:cs1kcd2o5e8hjftjdn2g" not found (not found)
unit-opensearch-5: 02:43:52 ERROR unit.opensearch/5.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-4: 02:43:52 ERROR unit.opensearch/4.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-4: 02:43:56 ERROR unit.opensearch/4.juju-log certificates:3: Error reading secret: 'NoneType' object has no attribute 'get'
unit-opensearch-3: 02:43:58 ERROR unit.opensearch/3.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-5: 02:43:59 ERROR unit.opensearch/5.juju-log Failed to delete voting exclusion: opensearch-5.dd7.
unit-opensearch-5: 02:43:59 ERROR unit.opensearch/5.juju-log Failed to delete shard allocation exclusion: opensearch-5.dd7.
unit-opensearch-5: 02:44:02 ERROR unit.opensearch/5.juju-log certificates:3: Error reading secret: 'NoneType' object has no attribute 'get'
unit-opensearch-3: 02:44:05 ERROR unit.opensearch/3.juju-log certificates:3: Error reading secret: 'NoneType' object has no attribute 'get'
machine-7: 02:45:42 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-7: 02:45:42 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-opensearch-6: 02:45:42 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-opensearch-6: 02:46:45 ERROR unit.opensearch/6.juju-log certificates:7: err:  / out: keytool error: java.lang.Exception: Keystore file does not exist: /var/snap/opensearch/current/etc/opensearch/certificates/ca.p12

unit-opensearch-6: 02:46:50 ERROR unit.opensearch/6.juju-log certificates:7: Cannot connect to the OpenSearch server...
unit-opensearch-6: 02:46:51 ERROR unit.opensearch/6.juju-log certificates:7: Cannot connect to the OpenSearch server...
unit-opensearch-6: 02:46:51 ERROR unit.opensearch/6.juju-log certificates:7: Cannot connect to the OpenSearch server...
unit-opensearch-6: 02:46:54 ERROR unit.opensearch/6.juju-log certificates:7: Cannot connect to the OpenSearch server...
unit-opensearch-6: 02:46:57 ERROR unit.opensearch/6.juju-log certificates:7: Cannot connect to the OpenSearch server...
unit-opensearch-6: 02:47:00 ERROR unit.opensearch/6.juju-log certificates:7: Cannot connect to the OpenSearch server...
machine-8: 02:52:52 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-8: 02:52:52 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-opensearch-7: 02:52:52 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-9: 02:52:52 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-9: 02:52:52 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-opensearch-8: 02:52:52 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-opensearch-8: 02:54:13 ERROR unit.opensearch/8.juju-log certificates:7: err:  / out: keytool error: java.lang.Exception: Keystore file does not exist: /var/snap/opensearch/current/etc/opensearch/certificates/ca.p12

unit-opensearch-8: 02:54:17 ERROR unit.opensearch/8.juju-log opensearch-peers:4: Cannot connect to the OpenSearch server...
unit-opensearch-7: 02:54:33 ERROR unit.opensearch/7.juju-log certificates:7: err:  / out: keytool error: java.lang.Exception: Keystore file does not exist: /var/snap/opensearch/current/etc/opensearch/certificates/ca.p12

unit-opensearch-7: 02:54:37 ERROR unit.opensearch/7.juju-log node-lock-fallback:5: Cannot connect to the OpenSearch server...
unit-opensearch-7: 02:54:38 ERROR unit.opensearch/7.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-7: 02:54:39 ERROR unit.opensearch/7.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-7: 02:54:40 ERROR unit.opensearch/7.juju-log certificates:7: Cannot connect to the OpenSearch server...
unit-opensearch-7: 02:54:41 ERROR unit.opensearch/7.juju-log certificates:7: Cannot connect to the OpenSearch server...
unit-opensearch-7: 02:54:43 ERROR unit.opensearch/7.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-7: 02:54:44 ERROR unit.opensearch/7.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-7: 02:54:45 ERROR unit.opensearch/7.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-7: 02:54:46 ERROR unit.opensearch/7.juju-log Cannot connect to the OpenSearch server...
unit-opensearch-8: 02:57:20 ERROR unit.opensearch/8.juju-log opensearch-peers:4: Cannot connect to the OpenSearch server...
unit-opensearch-7: 02:57:36 ERROR unit.opensearch/7.juju-log opensearch-peers:4: Cannot connect to the OpenSearch server...
unit-opensearch-7: 02:57:38 ERROR unit.opensearch/7.juju-log opensearch-peers:4: Cannot connect to the OpenSearch server...

[32mINFO    [0m pytest_operator.plugin:plugin.py:947 Forgetting model main...